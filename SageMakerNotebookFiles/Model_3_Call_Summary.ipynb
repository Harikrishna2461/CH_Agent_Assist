{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc58ef89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting redis\n",
      "  Downloading redis-5.0.2-py3-none-any.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: async-timeout>=4.0.3 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from redis) (4.0.3)\n",
      "Downloading redis-5.0.2-py3-none-any.whl (251 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.7/251.7 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: redis\n",
      "Successfully installed redis-5.0.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install redis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67e22501",
   "metadata": {},
   "outputs": [],
   "source": [
    "import redis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2601a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import base64\n",
    "import time\n",
    "import re\n",
    "from botocore.exceptions import ClientError\n",
    "import logging\n",
    "import redis\n",
    "\n",
    "bedrock_runtime = boto3.client(\n",
    "    service_name=\"bedrock-runtime\",\n",
    "    region_name=\"us-east-1\",\n",
    ")\n",
    "\n",
    "bedrock = boto3.client(\n",
    "    service_name='bedrock', \n",
    "    region_name='us-east-1'\n",
    ")\n",
    "\n",
    "brt = boto3.client(service_name='bedrock-runtime')\n",
    "\n",
    "##Processing data to fetch role and content\n",
    "def data_preprocessing(data):\n",
    "    #data = json_data['Records'][0][\"body\"]\n",
    "    convo = \"\"\n",
    "    content = json.loads(data[\"body\"])[\"body\"][\"transcript\"][0][\"Content\"]\n",
    "    role = json.loads(data[\"body\"])[\"body\"][\"transcript\"][0][\"ParticipantRole\"]\n",
    "    convo = convo + role + \" : \" + content\n",
    "    \n",
    "    return convo\n",
    "\n",
    "def data_postprocessing(data):\n",
    "    result = \"\"\n",
    "    start_index = data.find(\"{\")\n",
    "    \n",
    "    if start_index == -1:\n",
    "        data1 = \"{\" + data\n",
    "    else:\n",
    "        data1 = data\n",
    "    \n",
    "    start_index_final = data.find(\"{\")    \n",
    "    print(f'start_index:{start_index_final}')\n",
    "    \n",
    "    end_char_indices = [i.start() for i in re.finditer(\"}\",data1)]\n",
    "    print(f'end_indices:{end_char_indices}')\n",
    "    end_index = end_char_indices[len(end_char_indices)-1]\n",
    "    print(f'end_index:{end_index}')\n",
    "    if end_index == len(data1)-1:\n",
    "        result = data1[start_index_final:]\n",
    "    else:\n",
    "        result = data1[start_index_final:end_index+1]\n",
    "    print(f'result:{result}')\n",
    "    \n",
    "    return result\n",
    "    \n",
    "def summarisation_prompt_generator(context):\n",
    "    prompt_llama = f\"\"\"\n",
    "Instruction: \"Summarise this call transcript between a patient and an agent and provide it in a precise paragraph : \" :\n",
    "\n",
    "{context}.\n",
    "             \n",
    "Response :  \n",
    "    \"\"\"\n",
    "    return prompt_llama\n",
    "    \n",
    "#Defining function to summarize context\n",
    "def load_llama2(bedrock_runtime , prompt , temp , top_p):\n",
    "    try:\n",
    "        body = {\n",
    "            \"prompt\" : prompt,\n",
    "            \"temperature\" : temp,\n",
    "            \"top_p\" : top_p,\n",
    "            \"max_gen_len\" : 1000\n",
    "            }\n",
    "\n",
    "        response = bedrock_runtime.invoke_model(\n",
    "            modelId=\"meta.llama2-13b-chat-v1\", body=json.dumps(body)\n",
    "        )\n",
    "\n",
    "        response_body = json.loads(response[\"body\"].read())\n",
    "        completion = response_body[\"generation\"]\n",
    "\n",
    "        return completion\n",
    "\n",
    "    except ClientError:\n",
    "        logging.error(\"Couldn't invoke Llama 2\")\n",
    "        raise\n",
    "    \n",
    "def SQS_Publisher(json_data):\n",
    "    try:\n",
    "        sqs = boto3.client('sqs',region_name='us-east-1')\n",
    "        # Define the SQS queue URL\n",
    "        queue_url = 'https://sqs.us-east-1.amazonaws.com/383299343633/ch-agent-assist-sqs'\n",
    "        response = sqs.send_message(QueueUrl= queue_url,MessageBody=json.dumps(json_data) )\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "def SQS_data_postprocessing(event,data):\n",
    "    json_response = {\n",
    "            \"stream\": \"SUMMARY_DATA\",\n",
    "            \"streamConnectionId\": json.loads(event[\"Records\"][0]['body'])[\"streamConnectionId\"],\n",
    "             \"body\": {\n",
    "                 \"transactionId\": \"f830e890-3ff2-4fdc-a08e-dd9b78a2dc28\",\n",
    "                  \"contactId\": json.loads(event[\"Records\"][0]['body'])[\"streamConnectionId\"],\n",
    "            \"form_data\": data,\n",
    "                     }  \n",
    "            }\n",
    "    return json_response\n",
    "    \n",
    "def lambda_handler(event,context):\n",
    "    final_transcript = \"\"\n",
    "    #print(f'lambda_handler--Received_input : {event}.')\n",
    "    for i in range(len(event[\"Records\"])):\n",
    "        final_transcript += \"\\n\" + data_preprocessing(event[\"Records\"][i])\n",
    "    #print(f'lambda_handler--output_after_preprocessing_data : {final_transcript}.')\n",
    "    \n",
    "    prompt_summary = summarisation_prompt_generator(final_transcript)\n",
    "    #print(f'lambda_handler--generated_prompt : {prompt_summary}.')\n",
    "    summary_data = load_llama2(bedrock_runtime,prompt_summary,0.5,0.9)\n",
    "    print(f'lambda_handler--output_from_the_llm_model : {summary_data}.')\n",
    "    sqs_data = SQS_data_postprocessing(event,summary_data)\n",
    "    #print(f'lambda_handler--data_to_be_sent_to_SQS_after_postprocessing_json_output_of_model : {sqs_data}.')\n",
    "    ##SQS_Publisher(sqs_data)\n",
    "    ##print(f'lambda_handler--data_sent_to_sqs_sucessfully.')\n",
    "    #return {\"statusCode\": 200,\"body\": \"Data Sent to SQS Sucessfully\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae152000",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import base64\n",
    "import time\n",
    "import re\n",
    "from botocore.exceptions import ClientError\n",
    "import logging\n",
    "import redis\n",
    "import os\n",
    "\n",
    "bedrock_runtime = boto3.client(\n",
    "    service_name=\"bedrock-runtime\",\n",
    "    region_name=\"us-east-1\",\n",
    ")\n",
    "\n",
    "bedrock = boto3.client(\n",
    "    service_name='bedrock', \n",
    "    region_name='us-east-1'\n",
    ")\n",
    "\n",
    "brt = boto3.client(service_name='bedrock-runtime')\n",
    "\n",
    "# Initialize Redis client\n",
    "redis_host = 'ch-agent-assist-redis-cluster-disabled-ro.tjyhst.ng.0001.use1.cache.amazonaws.com'\n",
    "redis_port = 6379 # Default Redis port is 6379\n",
    "redis_password = None  # None if no password\n",
    "redis_client = redis.Redis(host=redis_host, port=redis_port, password=redis_password, decode_responses=True)\n",
    "\n",
    "##Processing data to fetch role and content\n",
    "def data_preprocessing(data):\n",
    "        \n",
    "    json_str1 = '[' + data\n",
    "    json_str1 += ']'\n",
    "    json_str2 = json_str1.strip()\n",
    "\n",
    "    try:\n",
    "       # Parse the JSON string as a list of dictionaries\n",
    "       data_list = json.loads(json_str2)\n",
    "       convo = \"\"\n",
    "       # Iterate through each item in the list and print desired information\n",
    "       for data in data_list:\n",
    "            for transcript in data['transcript']:\n",
    "                participant_role = transcript['ParticipantRole']\n",
    "                content = transcript['Content']\n",
    "                convo += participant_role + \" : \" + content + \"\\n\"\n",
    "            #print(f'{participant_role} : {content}')\n",
    "                \n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error parsing JSON: {e}\")\n",
    "        \n",
    "    return convo\n",
    "\n",
    "def data_postprocessing(data):\n",
    "    result = \"\"\n",
    "    start_index = data.find(\"{\")\n",
    "    \n",
    "    if start_index == -1:\n",
    "        data1 = \"{\" + data\n",
    "    else:\n",
    "        data1 = data\n",
    "    \n",
    "    start_index_final = data.find(\"{\")    \n",
    "    print(f'start_index:{start_index_final}')\n",
    "    \n",
    "    end_char_indices = [i.start() for i in re.finditer(\"}\",data1)]\n",
    "    print(f'end_indices:{end_char_indices}')\n",
    "    end_index = end_char_indices[len(end_char_indices)-1]\n",
    "    print(f'end_index:{end_index}')\n",
    "    if end_index == len(data1)-1:\n",
    "        result = data1[start_index_final:]\n",
    "    else:\n",
    "        result = data1[start_index_final:end_index+1]\n",
    "    print(f'result:{result}')\n",
    "    \n",
    "    return result\n",
    "    \n",
    "def summarisation_prompt_generator(context):\n",
    "    prompt_llama = f\"\"\"\n",
    "Instruction: \"Summarise this call transcript between a patient and an agent and provide it in a precise paragraph : \" :\n",
    "\n",
    "{context}.\n",
    "             \n",
    "Response :  \n",
    "    \"\"\"\n",
    "    return prompt_llama\n",
    "    \n",
    "#Defining function to summarize context\n",
    "def load_llama2(bedrock_runtime , prompt , temp , top_p):\n",
    "    try:\n",
    "        body = {\n",
    "            \"prompt\" : prompt,\n",
    "            \"temperature\" : temp,\n",
    "            \"top_p\" : top_p,\n",
    "            \"max_gen_len\" : 1000\n",
    "            }\n",
    "\n",
    "        response = bedrock_runtime.invoke_model(\n",
    "            modelId=\"meta.llama2-13b-chat-v1\", body=json.dumps(body)\n",
    "        )\n",
    "\n",
    "        response_body = json.loads(response[\"body\"].read())\n",
    "        completion = response_body[\"generation\"]\n",
    "\n",
    "        return completion\n",
    "\n",
    "    except ClientError:\n",
    "        logging.error(\"Couldn't invoke Llama 2\")\n",
    "        raise\n",
    "    \n",
    "def SQS_Publisher(json_data):\n",
    "    try:\n",
    "        sqs = boto3.client('sqs',region_name='us-east-1')\n",
    "        # Define the SQS queue URL\n",
    "        queue_url = 'https://sqs.us-east-1.amazonaws.com/383299343633/ch-agent-assist-sqs'\n",
    "        response = sqs.send_message(QueueUrl= queue_url,MessageBody=json.dumps(json_data) )\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "def SQS_data_postprocessing(event,data):\n",
    "    json_response = {\n",
    "            \"stream\": \"SUMMARY_DATA\",\n",
    "            \"streamConnectionId\": json.loads(event[\"Records\"][0]['body'])[\"streamConnectionId\"],\n",
    "             \"body\": {\n",
    "                 \"transactionId\": \"f830e890-3ff2-4fdc-a08e-dd9b78a2dc28\",\n",
    "                  \"contactId\": json.loads(event[\"Records\"][0]['body'])[\"streamConnectionId\"],\n",
    "            \"form_data\": data,\n",
    "                     }  \n",
    "            }\n",
    "    return json_response\n",
    "    \n",
    "def lambda_handler(event,context):\n",
    "    #print(event) \n",
    "    # Initialize Redis client\n",
    "    #redis_host = 'ch-agent-assist-redis-cluster-disabled-ro.tjyhst.ng.0001.use1.cache.amazonaws.com:6379'\n",
    "    #redis_port =  6379  # Default Redis port is 6379\n",
    "    #redis_password = None  # None if no password\n",
    "    #redis_client = redis.Redis(host=redis_host, port=redis_port, password=redis_password, decode_responses=True)\n",
    "    key_to_read = json.loads(event[\"Records\"][0]['body'])[\"streamConnectionId\"] #event.get('conversation_id')\n",
    "    print(key_to_read)\n",
    "    # Check if the key exists and read the value from Redis\n",
    "    if key_to_read and redis_client.exists(key_to_read):\n",
    "        value = redis_client.get(key_to_read)\n",
    "        print(value) #.split(\"contactId\"))\n",
    "    else:\n",
    "        print('Key not found')\n",
    "        \n",
    "    #final_transcript = \"\"\n",
    "    #print(f'lambda_handler--Received_input : {event}.')\n",
    "    #for i in range(len(event[\"Records\"])):\n",
    "        #final_transcript += \"\\n\" + data_preprocessing(event[\"Records\"][i])\n",
    "    #print(f'lambda_handler--output_after_preprocessing_data : {final_transcript}.')\n",
    "    final_transcript = data_preprocessing(value)\n",
    "    print(final_transcript)\n",
    "    prompt_summary = summarisation_prompt_generator(final_transcript)\n",
    "    print(f'lambda_handler--generated_prompt : {prompt_summary}.')\n",
    "    summary_data = load_llama2(bedrock_runtime,prompt_summary,0.5,0.9)\n",
    "    print(f'lambda_handler--output_from_the_llm_model : {summary_data}.')\n",
    "    sqs_data = SQS_data_postprocessing(event,summary_data)\n",
    "    print(f'lambda_handler--data_to_be_sent_to_SQS_after_postprocessing_json_output_of_model : {sqs_data}.')\n",
    "    SQS_Publisher(sqs_data)\n",
    "    print(f'lambda_handler--data_sent_to_sqs_sucessfully.')\n",
    "    return {\"statusCode\": 200,\"body\": \"Data Sent to SQS Sucessfully\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20a4216",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p310",
   "language": "python",
   "name": "conda_tensorflow2_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
