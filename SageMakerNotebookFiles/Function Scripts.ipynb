{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4217be4e",
   "metadata": {},
   "source": [
    "# Form Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be693f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import base64\n",
    "import time\n",
    "import re\n",
    "from botocore.exceptions import ClientError\n",
    "import logging\n",
    "import redis\n",
    "\n",
    "bedrock_runtime = boto3.client(\n",
    "    service_name=\"bedrock-runtime\",\n",
    "    region_name=\"us-east-1\",\n",
    ")\n",
    "\n",
    "bedrock = boto3.client(\n",
    "    service_name='bedrock', \n",
    "    region_name='us-east-1'\n",
    ")\n",
    "\n",
    "def decoder(data):\n",
    "    decodedBytes = base64.b64decode(data)\n",
    "    decodedStr = decodedBytes.decode(\"ascii\") \n",
    "    json_str=json.loads(decodedStr)\n",
    "    return json_str\n",
    "\n",
    "##Processing data to fetch role and content\n",
    "def construct_call_conversation(data):\n",
    "    segments = json.loads(data)\n",
    "    convo = \"\" \n",
    "    # Extract transcripts, participant roles, and content\n",
    "    for segment in segments:\n",
    "        transcript = segment['transcript'][0]\n",
    "        participant_role = transcript['ParticipantRole']\n",
    "        content = transcript['Content']\n",
    "        convo += participant_role + \" : \" + content + \"\\n\"\n",
    "    \n",
    "    return convo\n",
    "\n",
    "def model_output_postprocessing(data):\n",
    "    result = \"\"\n",
    "    start_index = data.find(\"{\")\n",
    "    \n",
    "    if start_index == -1:\n",
    "        data1 = \"{\" + data\n",
    "    else:\n",
    "        data1 = data\n",
    "    \n",
    "    start_index_final = data.find(\"{\")    \n",
    "    print(f'start_index:{start_index_final}')\n",
    "    \n",
    "    end_char_indices = [i.start() for i in re.finditer(\"}\",data1)]\n",
    "\n",
    "    #end_index = end_char_indices[len(end_char_indices)-1]\n",
    "    \n",
    "    if len(end_char_indices) == 0:\n",
    "        data2 = data1 + '}'\n",
    "    else:\n",
    "        data2 = data1\n",
    "      \n",
    "    end_char_indices_1 = [i.start() for i in re.finditer(\"}\",data2)]\n",
    "    print(f'end_indices:{end_char_indices_1}')  \n",
    "    end_index = end_char_indices[len(end_char_indices)-1]\n",
    "    print(f'end_index:{end_index}')\n",
    "    \n",
    "    if end_index == len(data2)-1:\n",
    "        result = data2[start_index_final:]\n",
    "    else:\n",
    "        result = data2[start_index_final:end_index+1]\n",
    "    print(f'result:{result}')\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def enrollment_prompt_generator(conversation,entities):\n",
    "    prompt_claude = f\"\"\"Human: {conversation}\n",
    "\n",
    "    The above is a transcript between a call center agent and an insurance subscriber or patient.\n",
    "    From the above conversation, identify and extract the values for the following parameters {entities}.\n",
    "    Make sure you adhere to the list of entities extracted and create JSON with the exact key names passed and do not change the key names.\n",
    "    Include only the information present in the provided conversation and do no not make-up any information on your own.\n",
    "    \n",
    "\n",
    "    Output the results as a structured JSON containing only the extracted fields.\n",
    "    \n",
    "    \n",
    "    Strictly Follow the rules to provide ouput in JSON format and do not provide the extra sentence 'Here are the key entities extracted from the conversation before the JSON' as part of your response.\n",
    "\n",
    "    Assistant:\n",
    "    \"\"\"\n",
    "\n",
    "    return prompt_claude\n",
    "    \n",
    "#Defining function to connect to Bedrock LLM\n",
    "def load_claude2(bedrock_runtime , prompt , temp , top_p,top_k):\n",
    "    try:\n",
    "        body = {\n",
    "            \"prompt\": prompt,\n",
    "            \"temperature\": temp,\n",
    "            \"top_p\": top_p,\n",
    "            \"top_k\":top_k,\n",
    "            \"max_tokens_to_sample\": 1000\n",
    "            }\n",
    "\n",
    "        response = bedrock_runtime.invoke_model(\n",
    "            modelId=\"anthropic.claude-v2\", body=json.dumps(body), accept=\"application/json\", contentType=\"application/json\"\n",
    "                 )\n",
    "        \n",
    "        response_body = json.loads(response[\"body\"].read())\n",
    "        completion = response_body.get(\"completion\")\n",
    "\n",
    "        return completion\n",
    "\n",
    "    except ClientError:\n",
    "        logging.error(\"Couldn't invoke Llama 2\")\n",
    "        raise\n",
    "\n",
    "def get_prompt(bucket,file,prompt_category,required_prompt,conversation):\n",
    "    entities = \"name of patient, status of insurance, insurance number, demographic details etc.\"\n",
    "    s3 = boto3.client('s3') \n",
    "    response = s3.get_object(Bucket=bucket,Key=file)\n",
    "    content = response['Body'].read().decode('utf-8')\n",
    "    json_content = json.loads(content)\n",
    "    prompt = json_content[prompt_category][required_prompt].format(conversation=conversation,entities=entities)\n",
    "    \n",
    "    return prompt\n",
    "     \n",
    "def sns_publisher(json_data):\n",
    "    # Create an SNS client\n",
    "    sns = boto3.client('sns')\n",
    "    # Specify the topic ARN\n",
    "    topic_arn = 'arn:aws:sns:us-east-1:383299343633:ch-agent-assist-processor-sns.fifo'\n",
    "    # Publish JSON data to SNS topic\n",
    "    response = sns.publish(TopicArn=topic_arn,Message=json.dumps({'default': json.dumps(json_data)}),MessageStructure='json',MessageGroupId=json_data[\"streamConnectionId\"])\n",
    "    print(f\"SNS published : {response}\")\n",
    "    \n",
    "           \n",
    "def sns_data_postprocessing(event,json_data):\n",
    "    json_response = {\n",
    "            \"stream\": \"FORM_DATA\",\n",
    "            \"streamConnectionId\": json.loads(event[\"Records\"][0]['body'])[\"streamConnectionId\"],\n",
    "             \"body\": {\n",
    "                 \"transactionId\": \"f830e890-3ff2-4fdc-a08e-dd9b78a2dc28\",\n",
    "                  \"contactId\": json.loads(event[\"Records\"][0]['body'])[\"streamConnectionId\"],\n",
    "            \"form_data\": json_data,\n",
    "                     }  \n",
    "            }\n",
    "    return json_response  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3675877b",
   "metadata": {},
   "source": [
    "# Insight Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc9c4787",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import base64\n",
    "import time\n",
    "import re\n",
    "from botocore.exceptions import ClientError\n",
    "import logging\n",
    "import redis\n",
    "\n",
    "bedrock_runtime = boto3.client(\n",
    "    service_name=\"bedrock-runtime\",\n",
    "    region_name=\"us-east-1\",\n",
    ")\n",
    "\n",
    "bedrock = boto3.client(\n",
    "    service_name='bedrock', \n",
    "    region_name='us-east-1'\n",
    ")\n",
    "\n",
    "def decoder(data):\n",
    "    decodedBytes = base64.b64decode(data)\n",
    "    decodedStr = decodedBytes.decode(\"ascii\") \n",
    "    json_str=json.loads(decodedStr)\n",
    "    return json_str\n",
    "\n",
    "##Processing data to fetch role and content\n",
    "def construct_call_conversation(data):\n",
    "    segments = json.loads(data)\n",
    "    convo = \"\" \n",
    "    # Extract transcripts, participant roles, and content\n",
    "    for segment in segments:\n",
    "        transcript = segment['transcript'][0]\n",
    "        participant_role = transcript['ParticipantRole']\n",
    "        content = transcript['Content']\n",
    "        convo += participant_role + \" : \" + content + \"\\n\"\n",
    "    \n",
    "    return convo\n",
    "\n",
    "def model_output_postprocessing(data):\n",
    "    result = \"\"\n",
    "    start_index = data.find(\"{\")\n",
    "    end_char_indices = [i.start() for i in re.finditer(\"}\",data)]\n",
    "    end_index = end_char_indices[len(end_char_indices)-1]\n",
    "    result = data[start_index:end_index+1]\n",
    "    \n",
    "    return result\n",
    "\n",
    "#Defining function to connect to Bedrock LLM\n",
    "def load_claude2(bedrock_runtime , prompt , temp , top_p,top_k):\n",
    "    try:\n",
    "        body = {\n",
    "            \"prompt\": prompt,\n",
    "            \"temperature\": temp,\n",
    "            \"top_p\": top_p,\n",
    "            \"top_k\":top_k,\n",
    "            \"max_tokens_to_sample\": 1000\n",
    "            }\n",
    "\n",
    "        response = bedrock_runtime.invoke_model(\n",
    "            modelId=\"anthropic.claude-v2\", body=json.dumps(body), accept=\"application/json\", contentType=\"application/json\"\n",
    "                 )\n",
    "        \n",
    "        response_body = json.loads(response[\"body\"].read())\n",
    "        completion = response_body.get(\"completion\")\n",
    "\n",
    "        return completion\n",
    "\n",
    "    except ClientError:\n",
    "        logging.error(\"Couldn't invoke Llama 2\")\n",
    "        raise\n",
    "\n",
    "#Passing the payer vs pharmacy stats as part of the context\n",
    "\n",
    "def get_enrollment_prompt(bucket,file,prompt_category,required_prompt,conversation):\n",
    "    entities = \"name of patient, status of insurance, insurance number, demographic details etc.\"\n",
    "    s3 = boto3.client('s3') \n",
    "    response = s3.get_object(Bucket=bucket,Key=file)\n",
    "    content = response['Body'].read().decode('utf-8')\n",
    "    json_content = json.loads(content)\n",
    "    prompt = json_content[prompt_category][required_prompt].format(conversation=conversation,entities=entities)\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "def get_insights_prompt(bucket,file,prompt_category,required_prompt,insurance_provider):\n",
    "    entities = \"name of patient, status of insurance, insurance number, demographic details etc.\"\n",
    "    s3 = boto3.client('s3') \n",
    "    response = s3.get_object(Bucket=bucket,Key=file)\n",
    "    content = response['Body'].read().decode('utf-8')\n",
    "    json_content = json.loads(content)\n",
    "    prompt = json_content[prompt_category][required_prompt].format(insurance_provider=insurance_provider,insurance_statistics=insurance_statistics)\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "def enrollment_prompt_generator(conversation,entities):\n",
    "    prompt_claude = f\"\"\"Human: {conversation}\n",
    "\n",
    "    The above is a transcript between a call center agent and an insurance subscriber or patient. Identify and extract key entities such as {entities} from the transcript. Include only the information present.\n",
    "\n",
    "    Output the results as a structured JSON containing only the extracted fields.\n",
    "    \n",
    "    Strictly Follow the rules to provide ouput in JSON format and do not provide the extra sentence 'Here are the key entities extracted from the conversation before the JSON' as part of your response.\n",
    "\n",
    "    Assistant:\n",
    "    \"\"\"\n",
    "\n",
    "    return prompt_claude\n",
    "    \n",
    "def insights_prompt_generator(insurance_provider,insurance_statistics):\n",
    "    prompt_claude = \"\"\"Human: \n",
    " \n",
    "You are Agent assist tracking the Patient and agent conversation and help the agent recommend meaningful insights on the \n",
    "insurance and insurance details related insights like for example suggesting which pharmacy to select based on the\n",
    "patient's Insurance provider using metrics like how soon the pharmacy dispenses the medication to the patient.The lesser the\n",
    "number of days to dispense the medication,the higher are the chances of recommendation of that pharmacy.\n",
    "\n",
    "The patients's insurance provider is  \\\" \"\"\" + insurance_provider + \"\"\" \\\" and use the following json data to provide the insights:\n",
    "\\\" \"\"\" + insurance_statistics + \"\"\" \\\".\n",
    "\n",
    "In the Json Data,the keys represent the insurance provider and the value represents the pharmacy company and the number of days\n",
    "it takes to dispense the medication to the patient.\n",
    "\n",
    "Provide the response in a structured and easily readable format.\n",
    " \n",
    "Assistant:\n",
    "\"\"\"\n",
    "    return prompt_claude\n",
    "\n",
    "def sns_publisher(json_data):\n",
    "    # Create an SNS client\n",
    "    sns = boto3.client('sns')\n",
    "    # Specify the topic ARN\n",
    "    topic_arn = 'arn:aws:sns:us-east-1:383299343633:ch-agent-assist-processor-sns.fifo'\n",
    "    # Publish JSON data to SNS topic\n",
    "    response = sns.publish(TopicArn=topic_arn,Message=json.dumps({'default': json.dumps(json_data)}),MessageStructure='json',MessageGroupId=json_data[\"streamConnectionId\"])\n",
    "    print(f\"SNS published : {response}\")\n",
    "        \n",
    "def sns_data_postprocessing(event,insights_data):\n",
    "    json_response = {\n",
    "            \"stream\": \"INSIGHTS_DATA\",\n",
    "            \"streamConnectionId\": json.loads(event[\"Records\"][0]['body'])[\"streamConnectionId\"],\n",
    "             \"body\": {\n",
    "                 \"transactionId\": \"f830e890-3ff2-4fdc-a08e-dd9b78a2dc28\",\n",
    "                  \"contactId\": json.loads(event[\"Records\"][0]['body'])[\"streamConnectionId\"],\n",
    "            \"form_data\": insights_data,\n",
    "                     }  \n",
    "            }\n",
    "    return json_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3208e79",
   "metadata": {},
   "source": [
    "# Call Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54b4d8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import base64\n",
    "import time\n",
    "import re\n",
    "from botocore.exceptions import ClientError\n",
    "import logging\n",
    "import redis\n",
    "import os\n",
    "\n",
    "bedrock_runtime = boto3.client(\n",
    "    service_name=\"bedrock-runtime\",\n",
    "    region_name=\"us-east-1\",\n",
    ")\n",
    "\n",
    "bedrock = boto3.client(\n",
    "    service_name='bedrock', \n",
    "    region_name='us-east-1'\n",
    ")\n",
    "\n",
    "##Processing data to fetch role and content\n",
    "def construct_call_conversation(data):\n",
    "    segments = json.loads(data)\n",
    "    convo = \"\" \n",
    "    # Extract transcripts, participant roles, and content\n",
    "    for segment in segments:\n",
    "        transcript = segment['transcript'][0]\n",
    "        participant_role = transcript['ParticipantRole']\n",
    "        content = transcript['Content']\n",
    "        convo += participant_role + \" : \" + content + \"\\n\"\n",
    "        \n",
    "    return convo\n",
    "\n",
    "def model_output_postprocessing(data):\n",
    "    result = \"\"\n",
    "    start_index = data.find(\"{\")\n",
    "    \n",
    "    if start_index == -1:\n",
    "        data1 = \"{\" + data\n",
    "    else:\n",
    "        data1 = data\n",
    "    \n",
    "    start_index_final = data.find(\"{\")    \n",
    "    print(f'start_index:{start_index_final}')\n",
    "    \n",
    "    end_char_indices = [i.start() for i in re.finditer(\"}\",data1)]\n",
    "    print(f'end_indices:{end_char_indices}')\n",
    "    end_index = end_char_indices[len(end_char_indices)-1]\n",
    "    print(f'end_index:{end_index}')\n",
    "    if end_index == len(data1)-1:\n",
    "        result = data1[start_index_final:]\n",
    "    else:\n",
    "        result = data1[start_index_final:end_index+1]\n",
    "    print(f'result:{result}')\n",
    "    \n",
    "    return result\n",
    "    \n",
    "def summarisation_prompt_generator(context):\n",
    "    prompt_llama = f\"\"\"\n",
    "Instruction: \"Summarise this call transcript between a patient and an agent and include the information shared by the patient in a precise paragraph\":\n",
    "NOTE: Consider the below context as your only source of information and provide the response in a paragraph\n",
    "\n",
    "{context}\n",
    "             \n",
    "Response :  \n",
    "    \"\"\"\n",
    "    return prompt_llama\n",
    "    \n",
    "#Defining function to summarize context\n",
    "def load_llama2(bedrock_runtime , prompt , temp , top_p):\n",
    "    try:\n",
    "        body = {\n",
    "            \"prompt\" : prompt,\n",
    "            \"temperature\" : temp,\n",
    "            \"top_p\" : top_p,\n",
    "            \"max_gen_len\" : 1000\n",
    "            }\n",
    "\n",
    "        response = bedrock_runtime.invoke_model(\n",
    "            modelId=\"meta.llama2-13b-chat-v1\", body=json.dumps(body)\n",
    "        )\n",
    "\n",
    "        response_body = json.loads(response[\"body\"].read())\n",
    "        completion = response_body[\"generation\"]\n",
    "\n",
    "        return completion\n",
    "\n",
    "    except ClientError:\n",
    "        logging.error(\"Couldn't invoke Llama 2\")\n",
    "        raise\n",
    "    \n",
    "\n",
    "def sns_data_postprocessing(event,data):\n",
    "    json_response = {\n",
    "            \"stream\": \"SUMMARY\",\n",
    "            \"streamConnectionId\": json.loads(event[\"Records\"][0]['body'])[\"streamConnectionId\"],\n",
    "             \"body\": {\n",
    "                 \"transactionId\": \"f830e890-3ff2-4fdc-a08e-dd9b78a2dc28\",\n",
    "                  \"contactId\": json.loads(event[\"Records\"][0]['body'])[\"streamConnectionId\"],\n",
    "            \"SUMMARY\": data,\n",
    "                     }  \n",
    "            }\n",
    "    return json_response\n",
    "    \n",
    "def sns_publisher(json_data):\n",
    "    # Create an SNS client\n",
    "    sns = boto3.client('sns')\n",
    "    # Specify the topic ARN\n",
    "    topic_arn = 'arn:aws:sns:us-east-1:383299343633:ch-agent-assist-processor-sns.fifo'\n",
    "    # Publish JSON data to SNS topic\n",
    "    response = sns.publish(TopicArn=topic_arn,Message=json.dumps({'default': json.dumps(json_data)}),MessageStructure='json',MessageGroupId=json_data[\"streamConnectionId\"])\n",
    "    print(f\"SNS published : {response}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p310",
   "language": "python",
   "name": "conda_tensorflow2_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
