{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81f43391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: boto3 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (1.34.32)\n",
      "Requirement already satisfied: botocore<1.35.0,>=1.34.32 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from boto3) (1.34.32)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from boto3) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from botocore<1.35.0,>=1.34.32->boto3) (2.8.2)\n",
      "Requirement already satisfied: urllib3<2.1,>=1.25.4 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from botocore<1.35.0,>=1.34.32->boto3) (1.26.18)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.32->boto3) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "199a5c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3 \n",
    "bedrock_runtime = boto3.client(\n",
    "    service_name=\"bedrock-runtime\",\n",
    "    region_name=\"us-east-1\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f28be0c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package wordnet to /home/ec2-user/nltk_data...\n",
      "[nltk_data] Downloading package omw-1.4 to /home/ec2-user/nltk_data...\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/ec2-user/nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "agent : thank you for calling our support line . how can i assist you today ?\n",
      "patient : yes i 'm calling about my recent prescription .\n",
      "agent : sure i 'd be to help . can you please provide your name and date of birth ?\n",
      "patient : my name is john doe and my date of birth is january 1st 1980 .\n",
      "agent : thank you john . what seems to be the issue with your prescription ?\n",
      "patient : well i think there might be a mistake in the dosage instructions .\n",
      "agent : alright let me pull up your prescription information . could you please confirm the medication name and dosage ?\n",
      "patient : it 's for medication x and i 'm supposed to take 2 tablets twice a day .\n",
      "agent : okay let me check that for you .\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import boto3\n",
    "\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "module_path = \"..\"\n",
    "sys.path.append(os.path.abspath(module_path))\n",
    "\n",
    "#Condensing data \n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Sample transcript data\n",
    "transcript = \"\"\"\n",
    "Agent: Hello, thank you for calling our support line. How can I assist you today?\n",
    "Patient: Hi, yes, I'm calling about my recent prescription.\n",
    "Agent: Sure, I'd be happy to help. Can you please provide your name and date of birth?\n",
    "Patient: My name is John Doe, and my date of birth is January 1st, 1980.\n",
    "Agent: Thank you, John. What seems to be the issue with your prescription?\n",
    "Patient: Well, I think there might be a mistake in the dosage instructions.\n",
    "Agent: Alright, let me pull up your prescription information. Could you please confirm the medication name and dosage?\n",
    "Patient: It's for medication X, and I'm supposed to take 2 tablets twice a day.\n",
    "Agent: Okay, let me check that for you.\n",
    "\"\"\"\n",
    "\n",
    "# Define a list of common greetings\n",
    "greetings = ['hello', 'hi', 'hey', 'howdy','Okay','happy',',']\n",
    "\n",
    "transcript_list = transcript.split(\"\\n\")\n",
    "\n",
    "# Tokenize the transcript\n",
    "tokens = []\n",
    "for i in range(len(transcript_list)):\n",
    "    token = word_tokenize(transcript_list[i].lower())\n",
    "    tokens.append(token)\n",
    "#tokens = word_tokenize(transcript.lower())\n",
    "\n",
    "filtered_tokens = []\n",
    "for i in range(len(tokens)):\n",
    "    str1 = \"\"\n",
    "    for j in range(len(tokens[i])):\n",
    "        #if tokens[i][j] not in stopwords.words('english') and tokens[i][j] not in greetings:\n",
    "        if tokens[i][j] not in greetings:\n",
    "            if j == 0:\n",
    "                str1 += tokens[i][j]\n",
    "            else:\n",
    "                str1 += \" \"\n",
    "                str1 += tokens[i][j]\n",
    "    filtered_tokens.append(str1)\n",
    "# Filter out common greetings and stopwords\n",
    "#filtered_tokens = [word for word in tokens if word not in stopwords.words('english') and word not in greetings]\n",
    "\n",
    "for i in range(len(filtered_tokens)):\n",
    "    print(filtered_tokens[i])\n",
    "# Reconstruct the filtered transcript\n",
    "#filtered_transcript = ' '.join(filtered_tokens)\n",
    "\n",
    "#print(filtered_transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "698e7540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'agent : thank you for calling our support line . how can i assist you today ?',\n",
       " \"patient : yes i 'm calling about my recent prescription .\",\n",
       " \"agent : sure i 'd be to help . can you please provide your name and date of birth ?\",\n",
       " 'patient : my name is john doe and my date of birth is january 1st 1980 .',\n",
       " 'agent : thank you john . what seems to be the issue with your prescription ?',\n",
       " 'patient : well i think there might be a mistake in the dosage instructions .',\n",
       " 'agent : alright let me pull up your prescription information . could you please confirm the medication name and dosage ?',\n",
       " \"patient : it 's for medication x and i 'm supposed to take 2 tablets twice a day .\",\n",
       " 'agent : okay let me check that for you .',\n",
       " '']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffdaf2af",
   "metadata": {},
   "source": [
    "# Text Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78be9999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting meta\n",
      "  Downloading meta-1.0.2.tar.gz (49 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: meta\n",
      "  Building wheel for meta (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for meta: filename=meta-1.0.2-py3-none-any.whl size=59235 sha256=ccd88988f84673ceca70a1d5511ad0746fadbd27a06fd0e273bdb96346b49f78\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/92/39/0b/1c4852017b6fd8a642c0481ade113ebd0b0d14e3d06d631593\n",
      "Successfully built meta\n",
      "Installing collected packages: meta\n",
      "Successfully installed meta-1.0.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6e97a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q transformers einops accelerate langchain bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d0d06c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: huggingface-cli <command> [<args>]\r\n",
      "huggingface-cli: error: argument {env,login,whoami,logout,repo,upload,download,lfs-enable-largefiles,lfs-multipart-upload,scan-cache,delete-cache}: invalid choice: 'login\\u200d' (choose from 'env', 'login', 'whoami', 'logout', 'repo', 'upload', 'download', 'lfs-enable-largefiles', 'lfs-multipart-upload', 'scan-cache', 'delete-cache')\r\n"
     ]
    }
   ],
   "source": [
    "!huggingface-cli login‍"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "178eddab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_summariser_llama2(bedrock_runtime , prompt , temp , top_p):\n",
    "    try:\n",
    "        body = {\n",
    "            \"prompt\": prompt,\n",
    "            \"temperature\": temp,\n",
    "            \"top_p\": top_p,\n",
    "            \"max_gen_len\": 200\n",
    "            }\n",
    "\n",
    "        response = bedrock_runtime.invoke_model(\n",
    "            modelId=\"meta.llama2-13b-chat-v1\", body=json.dumps(body)\n",
    "        )\n",
    "\n",
    "        response_body = json.loads(response[\"body\"].read())\n",
    "        completion = response_body[\"generation\"]\n",
    "\n",
    "        return completion\n",
    "\n",
    "    except ClientError:\n",
    "        logger.error(\"Couldn't invoke Llama 2\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "325cabb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bert-score\n",
      "  Downloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torch>=1.0.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from bert-score) (2.2.0)\n",
      "Requirement already satisfied: pandas>=1.0.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from bert-score) (1.5.3)\n",
      "Requirement already satisfied: transformers>=3.0.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from bert-score) (4.37.2)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from bert-score) (1.26.1)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from bert-score) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.31.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from bert-score) (4.66.1)\n",
      "Requirement already satisfied: matplotlib in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from bert-score) (3.8.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from bert-score) (23.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from pandas>=1.0.1->bert-score) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from pandas>=1.0.1->bert-score) (2023.3.post1)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (3.12.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (4.9.0)\n",
      "Requirement already satisfied: sympy in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (1.12)\n",
      "Requirement already satisfied: networkx in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (3.2)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (2023.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.0.0->bert-score) (12.3.101)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from transformers>=3.0.0->bert-score) (0.20.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from transformers>=3.0.0->bert-score) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from transformers>=3.0.0->bert-score) (2023.10.3)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from transformers>=3.0.0->bert-score) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from transformers>=3.0.0->bert-score) (0.4.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from matplotlib->bert-score) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from matplotlib->bert-score) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from matplotlib->bert-score) (4.43.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from matplotlib->bert-score) (1.4.5)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from matplotlib->bert-score) (10.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from matplotlib->bert-score) (3.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from requests->bert-score) (3.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from requests->bert-score) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from requests->bert-score) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from requests->bert-score) (2023.7.22)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas>=1.0.1->bert-score) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from jinja2->torch>=1.0.0->bert-score) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from sympy->torch>=1.0.0->bert-score) (1.3.0)\n",
      "Installing collected packages: bert-score\n",
      "Successfully installed bert-score-0.3.13\r\n"
     ]
    }
   ],
   "source": [
    "!pip install bert-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ab6c4380",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForMaskedLM, BertModel\n",
    "from bert_score import BERTScorer\n",
    "\n",
    "def bert_scorer(reference,candidate):\n",
    "    scorer = BERTScorer(model_type='bert-base-uncased')\n",
    "    P, R, F1 = scorer.score([candidate], [reference])\n",
    "    return f\"BERTScore Precision: {P.mean():.4f}, Recall: {R.mean():.4f}, F1: {F1.mean():.4f}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6cc5c669",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_1 = '''\n",
    "Agent: Hello, thank you for calling our support line. How can I assist you today?\n",
    "Patient: Hi, yes, I'm calling about my recent prescription.\n",
    "Agent: Sure, I'd be happy to help. Can you please provide your name and date of birth?\n",
    "Patient: My name is John Doe, and my date of birth is January 1st, 1980.\n",
    "Agent: Thank you, John. What seems to be the issue with your prescription?\n",
    "Patient: Well, I think there might be a mistake in the dosage instructions.\n",
    "Agent: Alright, let me pull up your prescription information. Could you please confirm the medication name and dosage?\n",
    "Patient: It's for medication X, and I'm supposed to take 2 tablets twice a day.\n",
    "Agent: Okay, let me check that for you.\n",
    "'''\n",
    "\n",
    "example_summary_original = \"The patient, John Doe, is calling the support line about a prescription issue. He believes there might be a mistake in the dosage instructions. The agent confirms the medication name and dosage for medication X, which is to take 2 tablets twice a day. The agent then checks the information for the patient.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ce7dcade",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate = '''\n",
    "Agent : Good afternoon, thank you for calling ABC Company customer service.My name is Sarah, how can I assist you today? \n",
    "Patient : Hi Sarah, my name is John Smith.I'm calling because I haven't received my order yet, and it's been over a week since I placed it. \n",
    "Agent: I apologize for the inconvenience, John. Can you please provide me with your order number so I can look into this for you? \n",
    "Patient : Sure, it's #123456789. \n",
    "Agent : Thank you, John. Let me check on the status of your order. It looks like your package was delayed due to a backlog at our shipping facility. I'm really sorry about that. \n",
    "Patient : That's frustrating, but I understand. Is there an estimated delivery date for my order now? \n",
    "Agent : Yes, according to our system, your package is scheduled to be delivered by Friday of this week. Would you like me to expedite the shipping at no extra cost for the inconvenience? \n",
    "Patient: That would be great, thank you. I appreciate your help with this. \n",
    "AGent : Of course, John. I've upgraded your shipping to expedited, and you should receive a confirmation email shortly. Is there anything else I can assist you with? **Customer:** No, that's all for now. Thank you for your help, Sarah. \n",
    "Agent : You're welcome, John. If you have any further questions or concerns, don't hesitate to reach out. Thank you for choosing ABC Company, and have a great day!\n",
    "''' \n",
    "\n",
    "summary_original = \"John called ABC Company's customer service regarding a delayed order. CSR Sarah apologized for the delay and offered to expedite the shipping at no extra cost. John agreed, and Sarah upgraded the shipping method. John expressed gratitude, and the call ended with Sarah ensuring John's satisfaction and offering further assistance if needed.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e89f090c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Llama 2 is a new, more powerful, and more efficient language model developed by Meta AI. It is the successor to the original Llama language model, which was introduced in 2017. Llama 2 is designed to handle more complex and open-ended natural language tasks, such as conversational dialogue and text generation, and it is trained on a larger and more diverse dataset than the original Llama.\n",
      "\n",
      "Llama 2 uses a transformer architecture, which is a type of neural network that is particularly well-suited for natural language processing tasks. The model is trained on a large dataset of text from the internet, and it is designed to learn the patterns and structures of natural language. This allows it to generate coherent and contextually appropriate text, and to engage in conversation in a way that is natural and human-like.\n",
      "\n",
      "One of the key advantages of Llama 2 is its ability to handle multi-turn dialogue, which means that it can engage in conversations that involve multiple exchanges of information. This is a challenging task for language models, as it requires the ability to understand the context and history of the conversation, and to generate responses that are appropriate to the current state of the dialogue. Llama 2 is able to handle this task by using a combination of natural language understanding and generation techniques, such as attention mechanisms and sequence-to-sequence models.\n",
      "\n",
      "Overall, Llama 2 represents a significant advance in the field of natural language processing, and it has the potential to enable new applications and use cases for language models. Its ability to engage in conversational dialogue and generate coherent and contextually appropriate text makes it a powerful tool for a wide range of applications, from chatbots and virtual assistants to content generation and language translation.\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import json\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "def invoke_llama2(bedrock_runtime_client, prompt):\n",
    "        \"\"\"\n",
    "        Invokes the Meta Llama 2 large-language model to run an inference\n",
    "        using the input provided in the request body.\n",
    "\n",
    "        :param prompt: The prompt that you want Jurassic-2 to complete.\n",
    "        :return: Inference response from the model.\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            # The different model providers have individual request and response formats.\n",
    "            # For the format, ranges, and default values for Meta Llama 2 Chat, refer to:\n",
    "            # https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters-meta.html\n",
    "\n",
    "            body = {\n",
    "                \"prompt\": prompt,\n",
    "                \"temperature\": 0.5,\n",
    "                \"top_p\": 0.9,\n",
    "                \"max_gen_len\": 512,\n",
    "            }\n",
    "\n",
    "            # model_id = 'meta.llama2-13b-chat-v1'\n",
    "            model_id = 'meta.llama2-70b-chat-v1'\n",
    "            response = bedrock_runtime_client.invoke_model(\n",
    "                modelId=model_id, body=json.dumps(body)\n",
    "            )\n",
    "\n",
    "            response_body = json.loads(response[\"body\"].read())\n",
    "            completion = response_body[\"generation\"]\n",
    "\n",
    "            return completion\n",
    "\n",
    "        except ClientError:\n",
    "            logger.error(\"Couldn't invoke Llama 2\")\n",
    "            raise\n",
    "\n",
    "# management plane, use bedrock\n",
    "# brt = boto3.client(service_name='bedrock')\n",
    "# brt.list_foundation_models()\n",
    "brt = boto3.client(service_name='bedrock-runtime')\n",
    "result = invoke_llama2(brt, 'what is llama 2?')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6cbca0f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nThe patient, John Smith, called ABC Company's customer service to inquire about his order, which had been delayed for over a week. The agent, Sarah, apologized for the inconvenience and asked for the order number to investigate. After checking the status, Sarah explained that the package was delayed due to a backlog at the shipping facility, but assured John that it would be delivered by the end of the week. She also offered to expedite the shipping at no extra cost to make up for the delay. John accepted the offer and thanked Sarah for her help.\""
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt1 = f\"\"\"\n",
    "Instruction: \"Summarise this call transcript between a patient and an agent and provide it in a precise paragraph :\" \\n : \n",
    "{candidate}.\n",
    "             \n",
    "Response : \n",
    "           \"\"\"\n",
    "\n",
    "brt = boto3.client(service_name='bedrock-runtime')\n",
    "summary_1 = text_summariser_llama2(brt,prompt1,0,0.5)\n",
    "summary_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "06a58e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarise this call transcript between a patient and an agent and provide it in a precise paragraph : \n",
      "             \n",
      "Agent : Good afternoon, thank you for calling ABC Company customer service.My name is Sarah, how can I assist you today? \n",
      "Patient : Hi Sarah, my name is John Smith.I'm calling because I haven't received my order yet, and it's been over a week since I placed it. \n",
      "Agent: I apologize for the inconvenience, John. Can you please provide me with your order number so I can look into this for you? \n",
      "Patient : Sure, it's #123456789. \n",
      "Agent : Thank you, John. Let me check on the status of your order. It looks like your package was delayed due to a backlog at our shipping facility. I'm really sorry about that. \n",
      "Patient : That's frustrating, but I understand. Is there an estimated delivery date for my order now? \n",
      "Agent : Yes, according to our system, your package is scheduled to be delivered by Friday of this week. Would you like me to expedite the shipping at no extra cost for the inconvenience? \n",
      "Patient: That would be great, thank you. I appreciate your help with this. \n",
      "AGent : Of course, John. I've upgraded your shipping to expedited, and you should receive a confirmation email shortly. Is there anything else I can assist you with? **Customer:** No, that's all for now. Thank you for your help, Sarah. \n",
      "Agent : You're welcome, John. If you have any further questions or concerns, don't hesitate to reach out. Thank you for choosing ABC Company, and have a great day!\n",
      ".\n",
      "             \n",
      "For example if the transcript is :\n",
      "             \n",
      "Agent: Hello, thank you for calling our support line. How can I assist you today?\n",
      "Patient: Hi, yes, I'm calling about my recent prescription.\n",
      "Agent: Sure, I'd be happy to help. Can you please provide your name and date of birth?\n",
      "Patient: My name is John Doe, and my date of birth is January 1st, 1980.\n",
      "Agent: Thank you, John. What seems to be the issue with your prescription?\n",
      "Patient: Well, I think there might be a mistake in the dosage instructions.\n",
      "Agent: Alright, let me pull up your prescription information. Could you please confirm the medication name and dosage?\n",
      "Patient: It's for medication X, and I'm supposed to take 2 tablets twice a day.\n",
      "Agent: Okay, let me check that for you.\n",
      "\n",
      "             \n",
      "The summary should be : \n",
      "The patient, John Doe, is calling the support line about a prescription issue. He believes there might be a mistake in the dosage instructions. The agent confirms the medication name and dosage for medication X, which is to take 2 tablets twice a day. The agent then checks the information for the patient.\n",
      "           \n"
     ]
    }
   ],
   "source": [
    "template = f\"\"\"\n",
    "Instruction: \"Summarise this call transcript between a patient and an agent and provide it in a precise paragraph :\" \\n : \n",
    "{candidate}.\n",
    "             \n",
    "Response : \n",
    "           \"\"\"\n",
    "print(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "23ca5f8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_summariser_llama2(template,0.9,0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "59b6cd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = [0,0.5,0.9]\n",
    "top_p = [0.1,0.5,0.9]\n",
    "\n",
    "#prompt = f\"\"\"Summarise this call transcript between a patient and an agent and provide it in a precise paragraph : {candidate}\"\"\"\n",
    "prompt_llama = f\"\"\"\n",
    "Instruction: \"Summarise this call transcript between a patient and an agent and provide it in a precise paragraph :\" \\n : \n",
    "{example_1}.\n",
    "             \n",
    "Response : \n",
    "           \"\"\"\n",
    "hyper_parameters_tuning_scores = {}\n",
    "hyper_parameters_tuning_text_summaries = {}\n",
    "brt = boto3.client(service_name='bedrock-runtime')\n",
    "\n",
    "for t in temp:\n",
    "    str1 = \"\"\n",
    "    for p in top_p:\n",
    "        str1 = f\"[Temperate : {t} , top_p : {p}]\"\n",
    "        summary = text_summariser_llama2(brt,prompt_llama,t,p)\n",
    "        scores = bert_scorer(example_summary_original,summary)\n",
    "        hyper_parameters_tuning_text_summaries[str1] = summary \n",
    "        hyper_parameters_tuning_scores[str1] = scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0afda8e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[Temperate : 0 , top_p : 0.1] : \n",
      "\n",
      "Agent: John, I apologize for any inconvenience. It looks like there was indeed a mistake in the dosage instructions. The correct dosage for medication X is 1 tablet twice a day. I've updated the prescription information with the correct dosage. Would you like me to send a new prescription to your pharmacy?\n",
      "Patient: Yes, please. And can you also confirm that the medication is covered by my insurance?\n",
      "Agent: Yes, medication X is covered under your insurance plan. I've confirmed the coverage with your insurance provider. Would you like me to send the new prescription to your pharmacy now?\n",
      "Patient: Yes, please go ahead and do that. Thank you so much for your help.\n",
      "Agent: You're welcome, John. Is there anything else I can assist you with today?\n",
      "Patient: No, that's all. Thank you again\n",
      "\n",
      "\n",
      "[Temperate : 0 , top_p : 0.5] : \n",
      "\n",
      "Agent: John, I apologize for any inconvenience. It looks like there was indeed a mistake in the dosage instructions. The correct dosage for medication X is 1 tablet twice a day. I've updated the prescription information with the correct dosage. Would you like me to send a new prescription to your pharmacy?\n",
      "Patient: Yes, please. And can you also confirm that the medication is covered by my insurance?\n",
      "Agent: Yes, medication X is covered under your insurance plan. I've confirmed the coverage with your insurance provider. Would you like me to send the new prescription to your pharmacy now?\n",
      "Patient: Yes, please go ahead and do that. Thank you so much for your help.\n",
      "Agent: You're welcome, John. Is there anything else I can assist you with today?\n",
      "Patient: No, that's all. Thank you again\n",
      "\n",
      "\n",
      "[Temperate : 0 , top_p : 0.9] : \n",
      "\n",
      "Agent: John, I apologize for any inconvenience. It looks like there was indeed a mistake in the dosage instructions. The correct dosage for medication X is 1 tablet twice a day. I've updated the prescription information with the correct dosage. Would you like me to send a new prescription to your pharmacy?\n",
      "Patient: Yes, please. And can you also confirm that the new prescription will be covered by my insurance?\n",
      "Agent: Yes, I can confirm that the new prescription will be covered under your insurance plan. I've also added a note to the prescription to ensure that the pharmacist is aware of the correct dosage. Is there anything else I can assist you with today, John?\n",
      "Patient: No, that's all. Thank you for your help.\n",
      "Agent: You're welcome, John. Have a great day.\n",
      "\n",
      "\n",
      "[Temperate : 0.5 , top_p : 0.1] : \n",
      "\n",
      "Agent: John, I apologize for any inconvenience. It looks like there was an error in the dosage instructions. The correct dosage for medication X is 1 tablet twice a day. I've updated the prescription information with the correct dosage. Would you like me to send a new prescription to your pharmacy?\n",
      "Patient: Yes, please. And can you also confirm that the new prescription will be covered by my insurance?\n",
      "Agent: Yes, I can confirm that the new prescription will be covered under your insurance plan. I've also sent the updated prescription to your pharmacy, and they should be able to fill it for you within the next 24 hours. Is there anything else I can assist you with today, John?\n",
      "Patient: No, that's all. Thank you for your help.\n",
      "Agent: You're welcome, John. Have a great day.\n",
      "\n",
      "\n",
      "[Temperate : 0.5 , top_p : 0.5] : \n",
      "\n",
      "Agent: John, I apologize for any inconvenience. It looks like there was indeed a mistake in the dosage instructions. The correct dosage for medication X is 1 tablet twice a day. I've updated the prescription information with the correct dosage. Would you like me to send a new prescription to your pharmacy?\n",
      "Patient: Yes, please. And can you also confirm that the medication is covered by my insurance?\n",
      "Agent: Yes, medication X is covered under your insurance plan. I've confirmed the coverage with your insurance provider. Would you like me to send the new prescription to your pharmacy now?\n",
      "Patient: Yes, please go ahead and do that. Thank you so much for your help.\n",
      "Agent: You're welcome, John. Is there anything else I can assist you with today?\n",
      "Patient: No, that's all. Thank you again\n",
      "\n",
      "\n",
      "[Temperate : 0.5 , top_p : 0.9] : \n",
      "\n",
      "The patient, John Doe, called the support line to report a possible mistake in the dosage instructions for his medication X. He provided his name and date of birth, and the agent confirmed the medication name and dosage. The agent checked the prescription information and confirmed that the dosage instructions were correct. \n",
      "\n",
      "\n",
      "[Temperate : 0.9 , top_p : 0.1] : \n",
      "\n",
      "Agent: John, I apologize for any inconvenience. It looks like there was indeed a mistake in the dosage instructions. The correct dosage for medication X is 1 tablet twice a day. I've updated the prescription information with the correct dosage. Would you like me to send a new prescription to your pharmacy?\n",
      "Patient: Yes, please. And can you also confirm that the new prescription will be covered by my insurance?\n",
      "Agent: Yes, I can confirm that the new prescription will be covered under your insurance plan. I've also added a note to the prescription to ensure that the pharmacist is aware of the correct dosage. Is there anything else I can assist you with today, John?\n",
      "Patient: No, that's all. Thank you for your help.\n",
      "Agent: You're welcome, John. Have a great day.\n",
      "\n",
      "\n",
      "[Temperate : 0.9 , top_p : 0.5] : \n",
      "\n",
      "Agent: John, I apologize for any inconvenience this may have caused, but it looks like there was an error in the dosage instructions. The correct dosage for medication X is 1 tablet twice a day. I've updated the prescription information with the correct dosage. Is there anything else I can assist you with today?\n",
      "Patient: No, that's all. Thank you for your help.\n",
      "Agent: You're welcome, John. Please feel free to reach out if you have any other questions or concerns. Have a great day!\n",
      "\n",
      "\n",
      "[Temperate : 0.9 , top_p : 0.9] : \n",
      "\n",
      "The patient, John Doe, called the support line to inquire about a possible mistake in the dosage instructions for his recent prescription, medication X, which he is supposed to take 2 tablets twice a day. The agent confirmed the prescription information and clarified the dosage instructions.\n"
     ]
    }
   ],
   "source": [
    "keys1 = list(hyper_parameters_tuning_text_summaries.keys())\n",
    "for i in range(len(hyper_parameters_tuning_text_summaries)):\n",
    "    print(\"\\n\")\n",
    "    print(f\"{keys1[i]} : \")\n",
    "    print(f\"{hyper_parameters_tuning_text_summaries[keys1[i]]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "87cbe0e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Temperate : 0 , top_p : 0.1] : \n",
      "BERTScore Precision: 0.4778, Recall: 0.6425, F1: 0.5480\n",
      "[Temperate : 0 , top_p : 0.5] : \n",
      "BERTScore Precision: 0.4778, Recall: 0.6425, F1: 0.5480\n",
      "[Temperate : 0 , top_p : 0.9] : \n",
      "BERTScore Precision: 0.4987, Recall: 0.6560, F1: 0.5666\n",
      "[Temperate : 0.5 , top_p : 0.1] : \n",
      "BERTScore Precision: 0.4910, Recall: 0.6516, F1: 0.5600\n",
      "[Temperate : 0.5 , top_p : 0.5] : \n",
      "BERTScore Precision: 0.4778, Recall: 0.6425, F1: 0.5480\n",
      "[Temperate : 0.5 , top_p : 0.9] : \n",
      "BERTScore Precision: 0.7904, Recall: 0.7568, F1: 0.7733\n",
      "[Temperate : 0.9 , top_p : 0.1] : \n",
      "BERTScore Precision: 0.4987, Recall: 0.6560, F1: 0.5666\n",
      "[Temperate : 0.9 , top_p : 0.5] : \n",
      "BERTScore Precision: 0.4977, Recall: 0.6400, F1: 0.5600\n",
      "[Temperate : 0.9 , top_p : 0.9] : \n",
      "BERTScore Precision: 0.7877, Recall: 0.7964, F1: 0.7920\n"
     ]
    }
   ],
   "source": [
    "keys2 = list(hyper_parameters_tuning_scores.keys())\n",
    "for i in range(len(hyper_parameters_tuning_text_summaries)):\n",
    "    print(f\"{keys2[i]} : \")\n",
    "    print(f\"{hyper_parameters_tuning_scores[keys2[i]]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f17ec5d",
   "metadata": {},
   "source": [
    "The Best Value of Temperate is 0.5 and top_p is 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f02c54",
   "metadata": {},
   "source": [
    "# QnA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "682df7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_llama = f\"\"\"\n",
    "Instruction: \"Summarise this call transcript between a patient and an agent and provide it in a precise paragraph :\" \\n : \n",
    "{example_1}.\n",
    "             \n",
    "Response : \n",
    "           \"\"\"\n",
    "\n",
    "final_summary = text_summariser_llama2(brt,prompt_llama,0.5,0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "96c5c9f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The patient, John Doe, called the support line to inquire about his recent prescription. He mentioned that there might be a mistake in the dosage instructions. The agent confirmed the medication name and dosage and checked the prescription information. \n"
     ]
    }
   ],
   "source": [
    "print(final_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c1f1f8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '4b562443-bd40-4375-9933-234743d3970c',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'date': 'Tue, 13 Feb 2024 12:27:12 GMT',\n",
       "   'content-type': 'application/json',\n",
       "   'content-length': '17098',\n",
       "   'connection': 'keep-alive',\n",
       "   'x-amzn-requestid': '4b562443-bd40-4375-9933-234743d3970c'},\n",
       "  'RetryAttempts': 0},\n",
       " 'modelSummaries': [{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-tg1-large',\n",
       "   'modelId': 'amazon.titan-tg1-large',\n",
       "   'modelName': 'Titan Text Large',\n",
       "   'providerName': 'Amazon',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-image-generator-v1:0',\n",
       "   'modelId': 'amazon.titan-image-generator-v1:0',\n",
       "   'modelName': 'Titan Image Generator G1',\n",
       "   'providerName': 'Amazon',\n",
       "   'inputModalities': ['TEXT', 'IMAGE'],\n",
       "   'outputModalities': ['IMAGE'],\n",
       "   'customizationsSupported': ['FINE_TUNING'],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND', 'PROVISIONED'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-image-generator-v1',\n",
       "   'modelId': 'amazon.titan-image-generator-v1',\n",
       "   'modelName': 'Titan Image Generator G1',\n",
       "   'providerName': 'Amazon',\n",
       "   'inputModalities': ['TEXT', 'IMAGE'],\n",
       "   'outputModalities': ['IMAGE'],\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-embed-g1-text-02',\n",
       "   'modelId': 'amazon.titan-embed-g1-text-02',\n",
       "   'modelName': 'Titan Text Embeddings v2',\n",
       "   'providerName': 'Amazon',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['EMBEDDING'],\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-text-lite-v1:0:4k',\n",
       "   'modelId': 'amazon.titan-text-lite-v1:0:4k',\n",
       "   'modelName': 'Titan Text G1 - Lite',\n",
       "   'providerName': 'Amazon',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': ['FINE_TUNING', 'CONTINUED_PRE_TRAINING'],\n",
       "   'inferenceTypesSupported': ['PROVISIONED'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-text-lite-v1',\n",
       "   'modelId': 'amazon.titan-text-lite-v1',\n",
       "   'modelName': 'Titan Text G1 - Lite',\n",
       "   'providerName': 'Amazon',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-text-express-v1:0:8k',\n",
       "   'modelId': 'amazon.titan-text-express-v1:0:8k',\n",
       "   'modelName': 'Titan Text G1 - Express',\n",
       "   'providerName': 'Amazon',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': ['FINE_TUNING', 'CONTINUED_PRE_TRAINING'],\n",
       "   'inferenceTypesSupported': ['PROVISIONED'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-text-express-v1',\n",
       "   'modelId': 'amazon.titan-text-express-v1',\n",
       "   'modelName': 'Titan Text G1 - Express',\n",
       "   'providerName': 'Amazon',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-embed-text-v1:2:8k',\n",
       "   'modelId': 'amazon.titan-embed-text-v1:2:8k',\n",
       "   'modelName': 'Titan Embeddings G1 - Text',\n",
       "   'providerName': 'Amazon',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['EMBEDDING'],\n",
       "   'responseStreamingSupported': False,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['PROVISIONED'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-embed-text-v1',\n",
       "   'modelId': 'amazon.titan-embed-text-v1',\n",
       "   'modelName': 'Titan Embeddings G1 - Text',\n",
       "   'providerName': 'Amazon',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['EMBEDDING'],\n",
       "   'responseStreamingSupported': False,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-embed-image-v1:0',\n",
       "   'modelId': 'amazon.titan-embed-image-v1:0',\n",
       "   'modelName': 'Titan Multimodal Embeddings G1',\n",
       "   'providerName': 'Amazon',\n",
       "   'inputModalities': ['TEXT', 'IMAGE'],\n",
       "   'outputModalities': ['EMBEDDING'],\n",
       "   'customizationsSupported': ['FINE_TUNING'],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND', 'PROVISIONED'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-embed-image-v1',\n",
       "   'modelId': 'amazon.titan-embed-image-v1',\n",
       "   'modelName': 'Titan Multimodal Embeddings G1',\n",
       "   'providerName': 'Amazon',\n",
       "   'inputModalities': ['TEXT', 'IMAGE'],\n",
       "   'outputModalities': ['EMBEDDING'],\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/stability.stable-diffusion-xl',\n",
       "   'modelId': 'stability.stable-diffusion-xl',\n",
       "   'modelName': 'SDXL 0.8',\n",
       "   'providerName': 'Stability AI',\n",
       "   'inputModalities': ['TEXT', 'IMAGE'],\n",
       "   'outputModalities': ['IMAGE'],\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/stability.stable-diffusion-xl-v0',\n",
       "   'modelId': 'stability.stable-diffusion-xl-v0',\n",
       "   'modelName': 'SDXL 0.8',\n",
       "   'providerName': 'Stability AI',\n",
       "   'inputModalities': ['TEXT', 'IMAGE'],\n",
       "   'outputModalities': ['IMAGE'],\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/stability.stable-diffusion-xl-v1:0',\n",
       "   'modelId': 'stability.stable-diffusion-xl-v1:0',\n",
       "   'modelName': 'SDXL 1.0',\n",
       "   'providerName': 'Stability AI',\n",
       "   'inputModalities': ['TEXT', 'IMAGE'],\n",
       "   'outputModalities': ['IMAGE'],\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['PROVISIONED'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/stability.stable-diffusion-xl-v1',\n",
       "   'modelId': 'stability.stable-diffusion-xl-v1',\n",
       "   'modelName': 'SDXL 1.0',\n",
       "   'providerName': 'Stability AI',\n",
       "   'inputModalities': ['TEXT', 'IMAGE'],\n",
       "   'outputModalities': ['IMAGE'],\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/ai21.j2-grande-instruct',\n",
       "   'modelId': 'ai21.j2-grande-instruct',\n",
       "   'modelName': 'J2 Grande Instruct',\n",
       "   'providerName': 'AI21 Labs',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': False,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/ai21.j2-jumbo-instruct',\n",
       "   'modelId': 'ai21.j2-jumbo-instruct',\n",
       "   'modelName': 'J2 Jumbo Instruct',\n",
       "   'providerName': 'AI21 Labs',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': False,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/ai21.j2-mid',\n",
       "   'modelId': 'ai21.j2-mid',\n",
       "   'modelName': 'Jurassic-2 Mid',\n",
       "   'providerName': 'AI21 Labs',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': False,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/ai21.j2-mid-v1',\n",
       "   'modelId': 'ai21.j2-mid-v1',\n",
       "   'modelName': 'Jurassic-2 Mid',\n",
       "   'providerName': 'AI21 Labs',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': False,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/ai21.j2-ultra',\n",
       "   'modelId': 'ai21.j2-ultra',\n",
       "   'modelName': 'Jurassic-2 Ultra',\n",
       "   'providerName': 'AI21 Labs',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': False,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/ai21.j2-ultra-v1',\n",
       "   'modelId': 'ai21.j2-ultra-v1',\n",
       "   'modelName': 'Jurassic-2 Ultra',\n",
       "   'providerName': 'AI21 Labs',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': False,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-instant-v1:2:100k',\n",
       "   'modelId': 'anthropic.claude-instant-v1:2:100k',\n",
       "   'modelName': 'Claude Instant',\n",
       "   'providerName': 'Anthropic',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['PROVISIONED'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-instant-v1',\n",
       "   'modelId': 'anthropic.claude-instant-v1',\n",
       "   'modelName': 'Claude Instant',\n",
       "   'providerName': 'Anthropic',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-v1',\n",
       "   'modelId': 'anthropic.claude-v1',\n",
       "   'modelName': 'Claude',\n",
       "   'providerName': 'Anthropic',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND'],\n",
       "   'modelLifecycle': {'status': 'LEGACY'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-v2:0:18k',\n",
       "   'modelId': 'anthropic.claude-v2:0:18k',\n",
       "   'modelName': 'Claude',\n",
       "   'providerName': 'Anthropic',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['PROVISIONED'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-v2:0:100k',\n",
       "   'modelId': 'anthropic.claude-v2:0:100k',\n",
       "   'modelName': 'Claude',\n",
       "   'providerName': 'Anthropic',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['PROVISIONED'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-v2:1:18k',\n",
       "   'modelId': 'anthropic.claude-v2:1:18k',\n",
       "   'modelName': 'Claude',\n",
       "   'providerName': 'Anthropic',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['PROVISIONED'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-v2:1:200k',\n",
       "   'modelId': 'anthropic.claude-v2:1:200k',\n",
       "   'modelName': 'Claude',\n",
       "   'providerName': 'Anthropic',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['PROVISIONED'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-v2:1',\n",
       "   'modelId': 'anthropic.claude-v2:1',\n",
       "   'modelName': 'Claude',\n",
       "   'providerName': 'Anthropic',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-v2',\n",
       "   'modelId': 'anthropic.claude-v2',\n",
       "   'modelName': 'Claude',\n",
       "   'providerName': 'Anthropic',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/cohere.command-text-v14:7:4k',\n",
       "   'modelId': 'cohere.command-text-v14:7:4k',\n",
       "   'modelName': 'Command',\n",
       "   'providerName': 'Cohere',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': ['FINE_TUNING'],\n",
       "   'inferenceTypesSupported': ['PROVISIONED'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/cohere.command-text-v14',\n",
       "   'modelId': 'cohere.command-text-v14',\n",
       "   'modelName': 'Command',\n",
       "   'providerName': 'Cohere',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/cohere.command-light-text-v14:7:4k',\n",
       "   'modelId': 'cohere.command-light-text-v14:7:4k',\n",
       "   'modelName': 'Command Light',\n",
       "   'providerName': 'Cohere',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': ['FINE_TUNING'],\n",
       "   'inferenceTypesSupported': ['PROVISIONED'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/cohere.command-light-text-v14',\n",
       "   'modelId': 'cohere.command-light-text-v14',\n",
       "   'modelName': 'Command Light',\n",
       "   'providerName': 'Cohere',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/cohere.embed-english-v3',\n",
       "   'modelId': 'cohere.embed-english-v3',\n",
       "   'modelName': 'Embed English',\n",
       "   'providerName': 'Cohere',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['EMBEDDING'],\n",
       "   'responseStreamingSupported': False,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/cohere.embed-multilingual-v3',\n",
       "   'modelId': 'cohere.embed-multilingual-v3',\n",
       "   'modelName': 'Embed Multilingual',\n",
       "   'providerName': 'Cohere',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['EMBEDDING'],\n",
       "   'responseStreamingSupported': False,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/meta.llama2-13b-chat-v1:0:4k',\n",
       "   'modelId': 'meta.llama2-13b-chat-v1:0:4k',\n",
       "   'modelName': 'Llama 2 Chat 13B',\n",
       "   'providerName': 'Meta',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['PROVISIONED'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/meta.llama2-13b-chat-v1',\n",
       "   'modelId': 'meta.llama2-13b-chat-v1',\n",
       "   'modelName': 'Llama 2 Chat 13B',\n",
       "   'providerName': 'Meta',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/meta.llama2-70b-chat-v1:0:4k',\n",
       "   'modelId': 'meta.llama2-70b-chat-v1:0:4k',\n",
       "   'modelName': 'Llama 2 Chat 70B',\n",
       "   'providerName': 'Meta',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': [],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/meta.llama2-70b-chat-v1',\n",
       "   'modelId': 'meta.llama2-70b-chat-v1',\n",
       "   'modelName': 'Llama 2 Chat 70B',\n",
       "   'providerName': 'Meta',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': ['ON_DEMAND'],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/meta.llama2-13b-v1:0:4k',\n",
       "   'modelId': 'meta.llama2-13b-v1:0:4k',\n",
       "   'modelName': 'Llama 2 13B',\n",
       "   'providerName': 'Meta',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': ['FINE_TUNING'],\n",
       "   'inferenceTypesSupported': [],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/meta.llama2-13b-v1',\n",
       "   'modelId': 'meta.llama2-13b-v1',\n",
       "   'modelName': 'Llama 2 13B',\n",
       "   'providerName': 'Meta',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': [],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/meta.llama2-70b-v1:0:4k',\n",
       "   'modelId': 'meta.llama2-70b-v1:0:4k',\n",
       "   'modelName': 'Llama 2 70B',\n",
       "   'providerName': 'Meta',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': ['FINE_TUNING'],\n",
       "   'inferenceTypesSupported': [],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/meta.llama2-70b-v1',\n",
       "   'modelId': 'meta.llama2-70b-v1',\n",
       "   'modelName': 'Llama 2 70B',\n",
       "   'providerName': 'Meta',\n",
       "   'inputModalities': ['TEXT'],\n",
       "   'outputModalities': ['TEXT'],\n",
       "   'responseStreamingSupported': True,\n",
       "   'customizationsSupported': [],\n",
       "   'inferenceTypesSupported': [],\n",
       "   'modelLifecycle': {'status': 'ACTIVE'}}]}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import boto3 \n",
    "bedrock = boto3.client(\n",
    "    service_name='bedrock', \n",
    "    region_name='us-east-1'\n",
    ")\n",
    "\n",
    "bedrock.list_foundation_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec7c4b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Downloading langchain-0.1.6-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from langchain) (2.0.22)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from langchain) (3.8.6)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from langchain) (4.0.3)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
      "  Downloading dataclasses_json-0.6.4-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting langchain-community<0.1,>=0.0.18 (from langchain)\n",
      "  Downloading langchain_community-0.0.19-py3-none-any.whl.metadata (7.9 kB)\n",
      "Collecting langchain-core<0.2,>=0.1.22 (from langchain)\n",
      "  Downloading langchain_core-0.1.22-py3-none-any.whl.metadata (6.0 kB)\n",
      "Collecting langsmith<0.1,>=0.0.83 (from langchain)\n",
      "  Downloading langsmith-0.0.90-py3-none-any.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: numpy<2,>=1 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from langchain) (1.26.1)\n",
      "Collecting pydantic<3,>=1 (from langchain)\n",
      "  Downloading pydantic-2.6.1-py3-none-any.whl.metadata (83 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.5/83.5 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from langchain) (8.2.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.3.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Downloading marshmallow-3.20.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
      "Requirement already satisfied: anyio<5,>=3 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from langchain-core<0.2,>=0.1.22->langchain) (4.0.0)\n",
      "Collecting langsmith<0.1,>=0.0.83 (from langchain)\n",
      "  Downloading langsmith-0.0.87-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting packaging<24.0,>=23.2 (from langchain-core<0.2,>=0.1.22->langchain)\n",
      "  Using cached packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic<3,>=1->langchain)\n",
      "  Downloading annotated_types-0.6.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pydantic-core==2.16.2 (from pydantic<3,>=1->langchain)\n",
      "  Downloading pydantic_core-2.16.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.5 kB)\n",
      "Collecting typing-extensions>=4.6.1 (from pydantic<3,>=1->langchain)\n",
      "  Using cached typing_extensions-4.9.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from requests<3,>=2->langchain) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2023.7.22)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.22->langchain) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.22->langchain) (1.1.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
      "Downloading langchain-0.1.6-py3-none-any.whl (811 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m811.8/811.8 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading langchain_community-0.0.19-py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading langchain_core-0.1.22-py3-none-any.whl (239 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.4/239.4 kB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langsmith-0.0.87-py3-none-any.whl (55 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.4/55.4 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-2.6.1-py3-none-any.whl (394 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m394.8/394.8 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_core-2.16.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m50.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
      "Downloading marshmallow-3.20.2-py3-none-any.whl (49 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached packaging-23.2-py3-none-any.whl (53 kB)\n",
      "Using cached typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Installing collected packages: typing-extensions, packaging, jsonpatch, annotated-types, typing-inspect, pydantic-core, marshmallow, pydantic, dataclasses-json, langsmith, langchain-core, langchain-community, langchain\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.5.0\n",
      "    Uninstalling typing_extensions-4.5.0:\n",
      "      Successfully uninstalled typing_extensions-4.5.0\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 21.3\n",
      "    Uninstalling packaging-21.3:\n",
      "      Successfully uninstalled packaging-21.3\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.13.1 requires numpy<=1.24.3,>=1.22, but you have numpy 1.26.1 which is incompatible.\n",
      "tensorflow 2.13.1 requires typing-extensions<4.6.0,>=3.6.6, but you have typing-extensions 4.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed annotated-types-0.6.0 dataclasses-json-0.6.4 jsonpatch-1.33 langchain-0.1.6 langchain-community-0.0.19 langchain-core-0.1.22 langsmith-0.0.87 marshmallow-3.20.2 packaging-23.2 pydantic-2.6.1 pydantic-core-2.16.2 typing-extensions-4.9.0 typing-inspect-0.9.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f4cfc801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The patient, John Doe, called the support line to inquire about his recent prescription. He mentioned that there might be a mistake in the dosage instructions. The agent confirmed the medication name and dosage and checked the prescription information. \n"
     ]
    }
   ],
   "source": [
    "print(final_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c1b9b66a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" I'm afraid I don't have any additional information about dosage instructions beyond what we've already discussed. Since this was a friendly conversation without a specific medical context, I don't have any details about medications or dosage instructions to share. I'm limited in what I can say without a proper medical context. Let me know if you have any other questions!\""
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import boto3\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import Bedrock\n",
    "\n",
    "bedrock_runtime_claude = boto3.client(\n",
    "    service_name=\"bedrock-runtime\",\n",
    "    region_name=\"us-east-1\",\n",
    ")\n",
    "\n",
    "claude_prompt = f\"\"\"\n",
    "Human : You are an agent assistant who helps the human customer care agent answer the patient's/customer's query by using\n",
    "the information from the following Current conversation summary and providing a satisfactory answer to the patient/customer.\n",
    "\n",
    "Current conversation summary:\n",
    "<conversation_history>\n",
    "{final_summary}\n",
    "</conversation_history>\n",
    "\n",
    "Here is the human's next reply:\n",
    "<human_reply>\n",
    "{input}\n",
    "</human_reply>\n",
    "\n",
    "Assistant:\n",
    "\"\"\"\n",
    "\n",
    "model_id = \"anthropic.claude-v2\"\n",
    "model_kwargs =  { \n",
    "    \"max_tokens_to_sample\": 4096,\n",
    "    \"temperature\": 0.5,\n",
    "    \"top_k\": 250,\n",
    "    \"top_p\": 1,\n",
    "    \"stop_sequences\": [\"\\n\\nHuman\"],\n",
    "    \"prompt\": claude_prompt,\n",
    "}\n",
    "\n",
    "llm = Bedrock(\n",
    "    client=bedrock_runtime,\n",
    "    model_id=model_id,\n",
    "    model_kwargs=model_kwargs\n",
    ")\n",
    "\n",
    "conversation= ConversationChain(\n",
    "    llm=llm, verbose=False, memory=ConversationBufferMemory() #memory_chain\n",
    ")\n",
    "\n",
    "conversation.predict(input=\"Hey,before I can end the conversation,are there any other change in dosage instruction?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1090302",
   "metadata": {},
   "source": [
    "# Testing the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "3ef1eca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize the S3 client\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "# Specifying the bucket name and CSV file key\n",
    "bucket_name = 'agentassistuc2'\n",
    "file_key = 'Call_Conv_2_12.txt'\n",
    "\n",
    "# Specifying the file path where you want to save the CSV data locally (here in the sagemaker instance's jupyter lab)\n",
    "local_file_path = 'Call_Conv_Test_1.txt'\n",
    "\n",
    "# Download the file from S3 to a local file\n",
    "s3.download_file(bucket_name, file_key, local_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "3ce1774a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now you can work with the local text file as needed\n",
    "with open(local_file_path, 'r') as file:\n",
    "    text_data = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "7ba76c38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    Transcript: {\n",
      "      ParticipantId: 'AGENT',\n",
      "      ParticipantRole: 'AGENT',\n",
      "      Content: 'Improving. Uh, Okay? Mm hmm. Obviously.',\n",
      "      BeginOffsetMillis: 1257,\n",
      "      EndOffsetMillis: 9697,\n",
      "      Sentiment: 'NEUTRAL',\n",
      "      Id: 'fb29489e-d06b-48b1-8e0b-519f17c4a68e'\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    Transcript: {\n",
      "      ParticipantId: 'CUSTOMER',\n",
      "      ParticipantRole: 'CUSTOMER',\n",
      "      Content: 'Fine. Thank you. I think',\n",
      "      BeginOffsetMillis: 3047,\n",
      "      EndOffsetMillis: 8055,\n",
      "      Sentiment: 'POSITIVE',\n",
      "      Id: '7f6820ee-0487-4cbc-9b35-33e7c31e1d5d'\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    Transcript: {\n",
      "      ParticipantId: 'CUSTOMER',\n",
      "      ParticipantRole: 'CUSTOMER',\n",
      "      Content: 'A little bit. More even now.',\n",
      "      BeginOffsetMillis: 10457,\n",
      "      EndOffsetMillis: 16775,\n",
      "      Sentiment: 'POSITIVE',\n",
      "      Id: '43d73132-0645-4133-8488-26aa9eac95bc'\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    Transcript: {\n",
      "      ParticipantId: 'AGENT',\n",
      "      ParticipantRole: 'AGENT',\n",
      "      Content: \"Yeah, you're audible and disconnecting. Yeah.\",\n",
      "      BeginOffsetMillis: 17207,\n",
      "      EndOffsetMillis: 21155,\n",
      "      Sentiment: 'NEGATIVE',\n",
      "      Id: '87b9d041-dadb-435f-a92b-6588bf150eea'\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    Transcript: {\n",
      "      ParticipantId: 'AGENT',\n",
      "      ParticipantRole: 'AGENT',\n",
      "      Content: \"Now it's better.\",\n",
      "      BeginOffsetMillis: 21180,\n",
      "      EndOffsetMillis: 22005,\n",
      "      Sentiment: 'POSITIVE',\n",
      "      Id: 'b8e2cca3-4cec-4a86-a20f-86fc0dc00101'\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    Transcript: {\n",
      "      ParticipantId: 'CUSTOMER',\n",
      "      ParticipantRole: 'CUSTOMER',\n",
      "      Content: 'Okay?',\n",
      "      BeginOffsetMillis: 21307,\n",
      "      EndOffsetMillis: 21865,\n",
      "      Sentiment: 'NEUTRAL',\n",
      "      Id: '7d7cac42-9491-4c0e-bd34-f93764495e6d'\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    Transcript: {\n",
      "      ParticipantId: 'CUSTOMER',\n",
      "      ParticipantRole: 'CUSTOMER',\n",
      "      Content: 'Yes, yes.',\n",
      "      BeginOffsetMillis: 23097,\n",
      "      EndOffsetMillis: 23895,\n",
      "      Sentiment: 'NEUTRAL',\n",
      "      Id: '497687d0-1cca-42c0-ae85-4c07d18b369d'\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    Transcript: {\n",
      "      ParticipantId: 'AGENT',\n",
      "      ParticipantRole: 'AGENT',\n",
      "      Content: \"Let's have a few details from you. I'm gonna give you the full name.\",\n",
      "      BeginOffsetMillis: 25320,\n",
      "      EndOffsetMillis: 29805,\n",
      "      Sentiment: 'NEUTRAL',\n",
      "      Id: '36f02c1c-7fae-4e91-b72b-bae54d02e094'\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    Transcript: {\n",
      "      ParticipantId: 'CUSTOMER',\n",
      "      ParticipantRole: 'CUSTOMER',\n",
      "      Content: 'Mhm. Yes, Michael name is Raven common.',\n",
      "      BeginOffsetMillis: 29050,\n",
      "      EndOffsetMillis: 33065,\n",
      "      Sentiment: 'NEUTRAL',\n",
      "      Id: '2b9c0d6c-8b42-42c7-9793-e7a9920290d4'\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    Transcript: {\n",
      "      ParticipantId: 'AGENT',\n",
      "      ParticipantRole: 'AGENT',\n",
      "      Content: \"You can, uh, What's your, uh, date of birth?\",\n",
      "      BeginOffsetMillis: 34347,\n",
      "      EndOffsetMillis: 37075,\n",
      "      Sentiment: 'NEUTRAL',\n",
      "      Id: '977cdf75-8d0a-44bf-898b-010f81e947da'\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    Transcript: {\n",
      "      ParticipantId: 'CUSTOMER',\n",
      "      ParticipantRole: 'CUSTOMER',\n",
      "      Content: 'My date of birth. 20th May 1989',\n",
      "      BeginOffsetMillis: 38330,\n",
      "      EndOffsetMillis: 41625,\n",
      "      Sentiment: 'NEUTRAL',\n",
      "      Id: '08b277e9-dc2a-4286-b85f-6c93aba55461'\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    Transcript: {\n",
      "      ParticipantId: 'AGENT',\n",
      "      ParticipantRole: 'AGENT',\n",
      "      Content: \"What's your email address?\",\n",
      "      BeginOffsetMillis: 42867,\n",
      "      EndOffsetMillis: 44185,\n",
      "      Sentiment: 'NEUTRAL',\n",
      "      Id: '8c5b548b-f8b4-49eb-9bdb-8afbf97f9ec5'\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    Transcript: {\n",
      "      ParticipantId: 'CUSTOMER',\n",
      "      ParticipantRole: 'CUSTOMER',\n",
      "      Content: 'My email address is provided early. Active mail dot com. The email ID is At the end, right. It would be cerulean double a',\n",
      "      BeginOffsetMillis: 45440,\n",
      "      EndOffsetMillis: 56165,\n",
      "      Sentiment: 'NEUTRAL',\n",
      "      Id: 'c4383e94-4173-43d0-9201-a70851aa6981'\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    Transcript: {\n",
      "      ParticipantId: 'AGENT',\n",
      "      ParticipantRole: 'AGENT',\n",
      "      Content: 'Okay? Uh,',\n",
      "      BeginOffsetMillis: 57100,\n",
      "      EndOffsetMillis: 58635,\n",
      "      Sentiment: 'NEUTRAL',\n",
      "      Id: '70d7276d-4f11-4779-a606-e0b3bc203774'\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    Transcript: {\n",
      "      ParticipantId: 'CUSTOMER',\n",
      "      ParticipantRole: 'CUSTOMER',\n",
      "      Content: \"If it's a R A L double. I At gmail dot com.\",\n",
      "      BeginOffsetMillis: 57660,\n",
      "      EndOffsetMillis: 61125,\n",
      "      Sentiment: 'NEUTRAL',\n",
      "      Id: '70737b9c-48d2-40ee-baa6-90a31ae3c83f'\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    Transcript: {\n",
      "      ParticipantId: 'AGENT',\n",
      "      ParticipantRole: 'AGENT',\n",
      "      Content: \"What's your phone number?\",\n",
      "      BeginOffsetMillis: 61220,\n",
      "      EndOffsetMillis: 62405,\n",
      "      Sentiment: 'NEUTRAL',\n",
      "      Id: 'fb2c6f25-d1c3-4984-b5c5-5b3ea3f57d5f'\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    Transcript: {\n",
      "      ParticipantId: 'CUSTOMER',\n",
      "      ParticipantRole: 'CUSTOMER',\n",
      "      Content: 'My phone number is 974329498.',\n",
      "      BeginOffsetMillis: 63650,\n",
      "      EndOffsetMillis: 67217,\n",
      "      Sentiment: 'NEUTRAL',\n",
      "      Id: 'a48d64f3-8310-4fce-ba09-7d231f429d37'\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    Transcript: {\n",
      "      ParticipantId: 'AGENT',\n",
      "      ParticipantRole: 'AGENT',\n",
      "      Content: 'Okay?',\n",
      "      BeginOffsetMillis: 71670,\n",
      "      EndOffsetMillis: 72235,\n",
      "      Sentiment: 'NEUTRAL',\n",
      "      Id: '531046fa-ef92-444a-b07b-1829905f70a2'\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    Transcript: {\n",
      "      ParticipantId: 'CUSTOMER',\n",
      "      ParticipantRole: 'CUSTOMER',\n",
      "      Content: 'Yep. You mean be needing my address, right?',\n",
      "      BeginOffsetMillis: 76077,\n",
      "      EndOffsetMillis: 80507,\n",
      "      Sentiment: 'NEUTRAL',\n",
      "      Id: 'f584fc57-07bd-4b0d-b614-4b0b769db957'\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    Transcript: {\n",
      "      ParticipantId: 'AGENT',\n",
      "      ParticipantRole: 'AGENT',\n",
      "      Content: 'Yeah.',\n",
      "      BeginOffsetMillis: 81307,\n",
      "      EndOffsetMillis: 81775,\n",
      "      Sentiment: 'NEUTRAL',\n",
      "      Id: 'cef9e912-5a8c-4f92-994a-095962a0113d'\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    Transcript: {\n",
      "      ParticipantId: 'CUSTOMER',\n",
      "      ParticipantRole: 'CUSTOMER',\n",
      "      Content: 'Yeah, My address is the 1 25 38. 19th closed 16 minutes now. We came second stage Bangalore. Been there twice. 56 double 076.',\n",
      "      BeginOffsetMillis: 83157,\n",
      "      EndOffsetMillis: 95985,\n",
      "      Sentiment: 'NEUTRAL',\n",
      "      Id: 'b84b0aee-79b6-4f45-8614-738c6b64f4c5'\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    Transcript: {\n",
      "      ParticipantId: 'AGENT',\n",
      "      ParticipantRole: 'AGENT',\n",
      "      Content: 'Okay?',\n",
      "      BeginOffsetMillis: 98800,\n",
      "      EndOffsetMillis: 99335,\n",
      "      Sentiment: 'NEUTRAL',\n",
      "      Id: '419b3b34-752e-4477-8106-39f8509916f5'\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    Transcript: {\n",
      "      ParticipantId: 'CUSTOMER',\n",
      "      ParticipantRole: 'CUSTOMER',\n",
      "      Content: 'Mm hmm. Yeah.',\n",
      "      BeginOffsetMillis: 102230,\n",
      "      EndOffsetMillis: 103657,\n",
      "      Sentiment: 'NEUTRAL',\n",
      "      Id: '1e993995-872e-4b28-9d16-fbbd230feb16'\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    Transcript: {\n",
      "      ParticipantId: 'AGENT',\n",
      "      ParticipantRole: 'AGENT',\n",
      "      Content: \"Cool. Uh, That's all That's information I required from you.\",\n",
      "      BeginOffsetMillis: 103440,\n",
      "      EndOffsetMillis: 107467,\n",
      "      Sentiment: 'POSITIVE',\n",
      "      Id: 'b3d5330e-a4d1-4acb-abb8-bf08e33d8906'\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    Transcript: {\n",
      "      ParticipantId: 'AGENT',\n",
      "      ParticipantRole: 'AGENT',\n",
      "      Content: 'I will check and let you know. Thank you.',\n",
      "      BeginOffsetMillis: 107740,\n",
      "      EndOffsetMillis: 109815,\n",
      "      Sentiment: 'POSITIVE',\n",
      "      Id: 'abdb41a9-4ca0-457d-8e1d-b2a1539b50e4'\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    Transcript: {\n",
      "      ParticipantId: 'CUSTOMER',\n",
      "      ParticipantRole: 'CUSTOMER',\n",
      "      Content: 'Okay? Okay?',\n",
      "      BeginOffsetMillis: 108000,\n",
      "      EndOffsetMillis: 108995,\n",
      "      Sentiment: 'NEUTRAL',\n",
      "      Id: 'efd302bb-1f9d-45bc-b26c-cd8b9b841902'\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    Transcript: {\n",
      "      ParticipantId: 'CUSTOMER',\n",
      "      ParticipantRole: 'CUSTOMER',\n",
      "      Content: 'Sure, certainly.',\n",
      "      BeginOffsetMillis: 110330,\n",
      "      EndOffsetMillis: 111945,\n",
      "      Sentiment: 'NEUTRAL',\n",
      "      Id: '2a07c56a-ae82-427c-a093-d9b5be297f0d'\n",
      "    }\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(text_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "265070ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def preprocess_text_data(text_data):\n",
    "    # Replace single quotes with double quotes\n",
    "    text_data = text_data.replace(\"'\", '\"')\n",
    "    \n",
    "    # Add double quotes around keys\n",
    "    text_data = text_data.replace(\"{\", '{\"').replace(\":\", '\":')\n",
    "    \n",
    "    return text_data\n",
    "\n",
    "def extract_content_from_transcripts(text_data):\n",
    "    try:\n",
    "        text_data = preprocess_text_data(text_data)\n",
    "        \n",
    "        # Convert the text data to a list of dictionaries\n",
    "        transcript_list = json.loads(text_data)\n",
    "\n",
    "        # Initialize an empty list to store content from each transcript\n",
    "        content_list = []\n",
    "\n",
    "        # Iterate through each transcript dictionary and extract the content\n",
    "        for transcript in transcript_list:\n",
    "            str1 = \"\"\n",
    "            content = transcript.get('Transcript', {}).get('Content')\n",
    "            role = transcript.get('Transcript',{}).get('ParticipantRole')\n",
    "            str1 = str1 + role + \" : \" + content\n",
    "            if content:\n",
    "                content_list.append(str1)\n",
    "        \n",
    "        call_transcript = \"\"\n",
    "        for i in range(len(content_list)):\n",
    "            if i != len(content_list)-1:\n",
    "                call_transcript += content_list[i]\n",
    "                call_transcript += \"\\n\"\n",
    "            else:\n",
    "                call_transcript += content_list[i]\n",
    "            \n",
    "        return call_transcript\n",
    "\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"Invalid JSON format. Please provide valid JSON data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "82b6bf8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AGENT : Improving. Uh, Okay? Mm hmm. Obviously.\n",
      "CUSTOMER : Fine. Thank you. I think\n",
      "CUSTOMER : A little bit. More even now.\n"
     ]
    }
   ],
   "source": [
    "# Example text data\n",
    "text_data1 = '''\n",
    "[\n",
    "  {\n",
    "    \"Transcript\": {\n",
    "      \"ParticipantId\": \"AGENT\",\n",
    "      \"ParticipantRole\": \"AGENT\",\n",
    "      \"Content\": \"Improving. Uh, Okay? Mm hmm. Obviously.\",\n",
    "      \"BeginOffsetMillis\": 1257,\n",
    "      \"EndOffsetMillis\": 9697,\n",
    "      \"Sentiment\": \"NEUTRAL\",\n",
    "      \"Id\": \"fb29489e-d06b-48b1-8e0b-519f17c4a68e\"\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"Transcript\": {\n",
    "      \"ParticipantId\": \"CUSTOMER\",\n",
    "      \"ParticipantRole\": \"CUSTOMER\",\n",
    "      \"Content\": \"Fine. Thank you. I think\",\n",
    "      \"BeginOffsetMillis\": 3047,\n",
    "      \"EndOffsetMillis\": 8055,\n",
    "      \"Sentiment\": \"POSITIVE\",\n",
    "      \"Id\": \"7f6820ee-0487-4cbc-9b35-33e7c31e1d5d\"\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"Transcript\": {\n",
    "      \"ParticipantId\": \"CUSTOMER\",\n",
    "      \"ParticipantRole\": \"CUSTOMER\",\n",
    "      \"Content\": \"A little bit. More even now.\",\n",
    "      \"BeginOffsetMillis\": 10457,\n",
    "      \"EndOffsetMillis\": 16775,\n",
    "      \"Sentiment\": \"POSITIVE\",\n",
    "      \"Id\": \"43d73132-0645-4133-8488-26aa9eac95bc\"\n",
    "    }\n",
    "  }\n",
    "]\n",
    "'''\n",
    "\n",
    "# Extract content from each transcript\n",
    "content_list = extract_content_from_transcripts(text_data1)\n",
    "print(content_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "e7cf5573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid JSON format. Please provide valid JSON data.\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def extract_content_from_transcripts(text_data):\n",
    "    try:\n",
    "        # Preprocess the text data to make it valid JSON\n",
    "        text_data = text_data.replace(\"'\", '\"')\n",
    "        text_data = text_data.replace(\"Transcript\", '\"Transcript\"')\n",
    "        text_data = text_data.replace(\"ParticipantId\", '\"ParticipantId\"')\n",
    "        text_data = text_data.replace(\"ParticipantRole\", '\"ParticipantRole\"')\n",
    "        text_data = text_data.replace(\"Content\", '\"Content\"')\n",
    "        text_data = text_data.replace(\"BeginOffsetMillis\", '\"BeginOffsetMillis\"')\n",
    "        text_data = text_data.replace(\"EndOffsetMillis\", '\"EndOffsetMillis\"')\n",
    "        text_data = text_data.replace(\"Sentiment\", '\"Sentiment\"')\n",
    "        text_data = text_data.replace(\"Id\", '\"Id\"')\n",
    "\n",
    "        # Convert the preprocessed text data to a list of dictionaries\n",
    "        transcript_list = json.loads(text_data)\n",
    "\n",
    "        # Initialize an empty list to store content from each transcript\n",
    "        content_list = []\n",
    "\n",
    "        # Iterate through each transcript dictionary and extract the content\n",
    "        for transcript in transcript_list:\n",
    "            content = transcript.get('Transcript', {}).get('Content')\n",
    "            if content:\n",
    "                content_list.append(content)\n",
    "\n",
    "        return content_list\n",
    "\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"Invalid JSON format. Please provide valid JSON data.\")\n",
    "\n",
    "# Extract content from each transcript\n",
    "content_list = extract_content_from_transcripts(text_data)\n",
    "print(content_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "62662249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def extract_content_from_transcripts(text_data):\n",
    "    try:\n",
    "        # Define a regular expression pattern to extract content from each transcript\n",
    "        pattern = r\"'Content': '(.*?)'\"\n",
    "\n",
    "        # Use regular expression to find all matches of the pattern in the text data\n",
    "        content_matches = re.findall(pattern, text_data)\n",
    "\n",
    "        # Return the list of extracted content\n",
    "        return content_matches\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error:\", e)\n",
    "\n",
    "# Example text data\n",
    "text_data = '''\n",
    "[\n",
    "  {\n",
    "    Transcript: {\n",
    "      ParticipantId: 'AGENT',\n",
    "      ParticipantRole: 'AGENT',\n",
    "      Content: 'Improving. Uh, Okay? Mm hmm. Obviously.',\n",
    "      BeginOffsetMillis: 1257,\n",
    "      EndOffsetMillis: 9697,\n",
    "      Sentiment: 'NEUTRAL',\n",
    "      Id: 'fb29489e-d06b-48b1-8e0b-519f17c4a68e'\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    Transcript: {\n",
    "      ParticipantId: 'CUSTOMER',\n",
    "      ParticipantRole: 'CUSTOMER',\n",
    "      Content: 'Fine. Thank you. I think',\n",
    "      BeginOffsetMillis: 3047,\n",
    "      EndOffsetMillis: 8055,\n",
    "      Sentiment: 'POSITIVE',\n",
    "      Id: '7f6820ee-0487-4cbc-9b35-33e7c31e1d5d'\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    Transcript: {\n",
    "      ParticipantId: 'CUSTOMER',\n",
    "      ParticipantRole: 'CUSTOMER',\n",
    "      Content: 'A little bit. More even now.',\n",
    "      BeginOffsetMillis: 10457,\n",
    "      EndOffsetMillis: 16775,\n",
    "      Sentiment: 'POSITIVE',\n",
    "      Id: '43d73132-0645-4133-8488-26aa9eac95bc'\n",
    "    }\n",
    "  }\n",
    "]\n",
    "'''\n",
    "\n",
    "# Extract content from each transcript\n",
    "content_list = extract_content_from_transcripts(text_data)\n",
    "print(content_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "228aa0fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[\n",
      "  {\"\n",
      "    Transcript\": {\"\n",
      "      ParticipantId\": \"AGENT\",\n",
      "      ParticipantRole\": \"AGENT\",\n",
      "      Content\": \"Improving. Uh, Okay? Mm hmm. Obviously.\",\n",
      "      BeginOffsetMillis\": 1257,\n",
      "      EndOffsetMillis\": 9697,\n",
      "      Sentiment\": \"NEUTRAL\",\n",
      "      Id\": \"fb29489e-d06b-48b1-8e0b-519f17c4a68e\"\n",
      "    }\n",
      "  },\n",
      "  {\"\n",
      "    Transcript\": {\"\n",
      "      ParticipantId\": \"CUSTOMER\",\n",
      "      ParticipantRole\": \"CUSTOMER\",\n",
      "      Content\": \"Fine. Thank you. I think\",\n",
      "      BeginOffsetMillis\": 3047,\n",
      "      EndOffsetMillis\": 8055,\n",
      "      Sentiment\": \"POSITIVE\",\n",
      "      Id\": \"7f6820ee-0487-4cbc-9b35-33e7c31e1d5d\"\n",
      "    }\n",
      "  },\n",
      "  {\"\n",
      "    Transcript\": {\"\n",
      "      ParticipantId\": \"CUSTOMER\",\n",
      "      ParticipantRole\": \"CUSTOMER\",\n",
      "      Content\": \"A little bit. More even now.\",\n",
      "      BeginOffsetMillis\": 10457,\n",
      "      EndOffsetMillis\": 16775,\n",
      "      Sentiment\": \"POSITIVE\",\n",
      "      Id\": \"43d73132-0645-4133-8488-26aa9eac95bc\"\n",
      "    }\n",
      "  }\n",
      "]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(preprocess_text_data(text_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "94d91df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid JSON format. Please provide valid JSON data.\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Example text data\n",
    "text_data = '''\n",
    "[\n",
    "  {\n",
    "    Transcript: {\n",
    "      ParticipantId: 'AGENT',\n",
    "      ParticipantRole: 'AGENT',\n",
    "      Content: 'Improving. Uh, Okay? Mm hmm. Obviously.',\n",
    "      BeginOffsetMillis: 1257,\n",
    "      EndOffsetMillis: 9697,\n",
    "      Sentiment: 'NEUTRAL',\n",
    "      Id: 'fb29489e-d06b-48b1-8e0b-519f17c4a68e'\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    Transcript: {\n",
    "      ParticipantId: 'CUSTOMER',\n",
    "      ParticipantRole: 'CUSTOMER',\n",
    "      Content: 'Fine. Thank you. I think',\n",
    "      BeginOffsetMillis: 3047,\n",
    "      EndOffsetMillis: 8055,\n",
    "      Sentiment: 'POSITIVE',\n",
    "      Id: '7f6820ee-0487-4cbc-9b35-33e7c31e1d5d'\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    Transcript: {\n",
    "      ParticipantId: 'CUSTOMER',\n",
    "      ParticipantRole: 'CUSTOMER',\n",
    "      Content: 'A little bit. More even now.',\n",
    "      BeginOffsetMillis: 10457,\n",
    "      EndOffsetMillis: 16775,\n",
    "      Sentiment: 'POSITIVE',\n",
    "      Id: '43d73132-0645-4133-8488-26aa9eac95bc'\n",
    "    }\n",
    "  }\n",
    "]\n",
    "'''\n",
    "\n",
    "# Extract content from each transcript\n",
    "content_list = extract_content_from_transcripts(text_data)\n",
    "print(content_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "64a4010d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid JSON format. Please provide valid JSON data.\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "extracted_text_data = extract_content_from_transcripts(text_data)\n",
    "print(extracted_text_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p310",
   "language": "python",
   "name": "conda_tensorflow2_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
