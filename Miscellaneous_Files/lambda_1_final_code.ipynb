{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0185fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import base64\n",
    "import time\n",
    "import re\n",
    "from botocore.exceptions import ClientError\n",
    "import logging\n",
    "\n",
    "bedrock_runtime = boto3.client(\n",
    "    service_name=\"bedrock-runtime\",\n",
    "    region_name=\"us-east-1\",\n",
    ")\n",
    "\n",
    "bedrock = boto3.client(\n",
    "    service_name='bedrock', \n",
    "    region_name='us-east-1'\n",
    ")\n",
    "\n",
    "brt = boto3.client(service_name='bedrock-runtime')\n",
    "\n",
    "def decoder(data):\n",
    "    decodedBytes = base64.b64decode(data)\n",
    "    decodedStr = decodedBytes.decode(\"ascii\") \n",
    "    json_str=json.loads(decodedStr)\n",
    "    return json_str\n",
    "\n",
    "##Processing data to fetch role and content\n",
    "def data_preprocessing(data):\n",
    "    #data = json_data['Records'][0][\"body\"]\n",
    "    convo = \"\"\n",
    "    content = json.loads(data[\"Records\"][0][\"body\"])[\"body\"][\"transcript\"][0][\"Content\"]\n",
    "    role = json.loads(data[\"Records\"][0][\"body\"])[\"body\"][\"transcript\"][0][\"ParticipantRole\"]\n",
    "    convo = convo + role + \" : \" + content\n",
    "    #parsed_data = json.loads(data)\n",
    "    #content = data#[\"body\"]#[\"transcript\"]#[0]#[\"Content\"]\n",
    "    #role = data[\"body\"][\"transcript\"][0][\"ParticipantRole\"]\n",
    "    \n",
    "    #convo = \"\"\n",
    "    #for i in range(len(transcription['transcriptions'])):\n",
    "        #convo = convo + transcription['transcriptions'][i]['ParticipantRole'] + \": \" + transcription['transcriptions'][i]['Content']\n",
    "        #convo += \"\\n\"\n",
    "    #role = transcription[\"Segments\"][0][\"Transcript\"][\"ParticipantRole\"]\n",
    "    #content = transcription[\"Segments\"][0][\"Transcript\"][\"Content\"]\n",
    "    #convo = convo + role + \" : \" + content\n",
    "    \n",
    "    return convo\n",
    "\n",
    "def data_postprocessing(data):\n",
    "    result = \"\"\n",
    "    start_index = data.find(\"{\")\n",
    "    end_char_indices = [i.start() for i in re.finditer(\"}\",data)]\n",
    "    end_index = end_char_indices[len(end_char_indices)-1]\n",
    "    result = data[start_index:end_index+1]\n",
    "    \n",
    "    return result\n",
    "    \n",
    "#Defining function to connect to Bedrock LLM\n",
    "def load_claude2(bedrock_runtime , prompt , temp , top_p,top_k):\n",
    "    try:\n",
    "        body = {\n",
    "            \"prompt\": prompt,\n",
    "            \"temperature\": temp,\n",
    "            \"top_p\": top_p,\n",
    "            \"top_k\":top_k,\n",
    "            \"max_tokens_to_sample\": 1000\n",
    "            }\n",
    "\n",
    "        response = bedrock_runtime.invoke_model(\n",
    "            modelId=\"anthropic.claude-v2\", body=json.dumps(body), accept=\"application/json\", contentType=\"application/json\"\n",
    "                 )\n",
    "        \n",
    "        response_body = json.loads(response[\"body\"].read())\n",
    "        completion = response_body.get(\"completion\")\n",
    "\n",
    "        return completion\n",
    "\n",
    "    except ClientError:\n",
    "        logging.error(\"Couldn't invoke Llama 2\")\n",
    "        raise\n",
    "\n",
    "#Defining LLM function for the prompt generator for entity extraction  \n",
    "entities = \"name of patient, status of insurance, insurance number, demographic details etc.\"\n",
    "def enrollment_prompt_generator(conversation,entities):\n",
    "    prompt_claude = \"\"\"Human: \\\" \"\"\" + conversation + \"\"\" \\\"\n",
    " \n",
    "The above conversation is an automated transcript between a call centre agent and an insurance subscriber or \n",
    "patiet. I want to extract few key entities like \\\" \"\"\" + entities + \"\"\" \\\"\". All or some information may be present in this transcript.\n",
    "Extract the entities that you are able to find from this piece of call transcript.\n",
    " \n",
    "The output would be a structured json with only the extracted fields. Just print the exact output without any extra sentences at the end or beggining. \n",
    "No need to print any extra text. Also do not generate an answer if that is not found in the transcript.\n",
    " \n",
    "Assistant:\n",
    "\"\"\"\n",
    "    return prompt_claude\n",
    "\n",
    "# Lambda handler to intgerate with AWS\n",
    "def lambda_handler(event,context):\n",
    "    final_transcript = data_preprocessing(event)\n",
    "    prompt_enrollment = enrollment_prompt_generator(final_transcript,entities)\n",
    "    enrollment_data = load_claude2(bedrock_runtime,prompt_enrollment,0,0.9,1)\n",
    "    json_data = data_postprocessing(enrollment_data)\n",
    "    enrollment_json_object = json.loads(json_data)\n",
    "    return {\"statusCode\": 200,\"body\": json.dumps(enrollment_json_object)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345c4641",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import base64\n",
    "import time\n",
    "import re\n",
    "from botocore.exceptions import ClientError\n",
    "import logging\n",
    "\n",
    "bedrock_runtime = boto3.client(\n",
    "    service_name=\"bedrock-runtime\",\n",
    "    region_name=\"us-east-1\",\n",
    ")\n",
    "\n",
    "bedrock = boto3.client(\n",
    "    service_name='bedrock', \n",
    "    region_name='us-east-1'\n",
    ")\n",
    "\n",
    "brt = boto3.client(service_name='bedrock-runtime')\n",
    "\n",
    "def decoder(data):\n",
    "    decodedBytes = base64.b64decode(data)\n",
    "    decodedStr = decodedBytes.decode(\"ascii\") \n",
    "    json_str=json.loads(decodedStr)\n",
    "    return json_str\n",
    "\n",
    "##Processing data to fetch role and content\n",
    "def data_preprocessing(data):\n",
    "    #data = json_data['Records'][0][\"body\"]\n",
    "    convo = \"\"\n",
    "    content = json.loads(data[\"body\"])[\"body\"][\"transcript\"][0][\"Content\"]\n",
    "    role = json.loads(data[\"body\"])[\"body\"][\"transcript\"][0][\"ParticipantRole\"]\n",
    "    convo = convo + role + \" : \" + content\n",
    "    #parsed_data = json.loads(data)\n",
    "    #content = data#[\"body\"]#[\"transcript\"]#[0]#[\"Content\"]\n",
    "    #role = data[\"body\"][\"transcript\"][0][\"ParticipantRole\"]\n",
    "    \n",
    "    #convo = \"\"\n",
    "    #for i in range(len(transcription['transcriptions'])):\n",
    "        #convo = convo + transcription['transcriptions'][i]['ParticipantRole'] + \": \" + transcription['transcriptions'][i]['Content']\n",
    "        #convo += \"\\n\"\n",
    "    #role = transcription[\"Segments\"][0][\"Transcript\"][\"ParticipantRole\"]\n",
    "    #content = transcription[\"Segments\"][0][\"Transcript\"][\"Content\"]\n",
    "    #convo = convo + role + \" : \" + content\n",
    "    \n",
    "    return convo\n",
    "\n",
    "def data_postprocessing(data):\n",
    "    result = \"\"\n",
    "    start_index = data.find(\"{\")\n",
    "    end_char_indices = [i.start() for i in re.finditer(\"}\",data)]\n",
    "    end_index = end_char_indices[len(end_char_indices)-1]\n",
    "    result = data[start_index:end_index+1]\n",
    "    \n",
    "    return result\n",
    "    \n",
    "#Defining function to connect to Bedrock LLM\n",
    "def load_claude2(bedrock_runtime , prompt , temp , top_p,top_k):\n",
    "    try:\n",
    "        body = {\n",
    "            \"prompt\": prompt,\n",
    "            \"temperature\": temp,\n",
    "            \"top_p\": top_p,\n",
    "            \"top_k\":top_k,\n",
    "            \"max_tokens_to_sample\": 1000\n",
    "            }\n",
    "\n",
    "        response = bedrock_runtime.invoke_model(\n",
    "            modelId=\"anthropic.claude-v2\", body=json.dumps(body), accept=\"application/json\", contentType=\"application/json\"\n",
    "                 )\n",
    "        \n",
    "        response_body = json.loads(response[\"body\"].read())\n",
    "        completion = response_body.get(\"completion\")\n",
    "\n",
    "        return completion\n",
    "\n",
    "    except ClientError:\n",
    "        logging.error(\"Couldn't invoke Llama 2\")\n",
    "        raise\n",
    "\n",
    "#Defining LLM function for the prompt generator for entity extraction  \n",
    "entities = \"name of patient, status of insurance, insurance number, demographic details etc.\"\n",
    "def enrollment_prompt_generator(conversation,entities):\n",
    "    prompt_claude = \"\"\"Human: \\\" \"\"\" + conversation + \"\"\" \\\"\n",
    " \n",
    "The above conversation is an automated transcript between a call centre agent and an insurance subscriber or \n",
    "patiet. I want to extract few key entities like \\\" \"\"\" + entities + \"\"\" \\\"\". All or some information may be present in this transcript.\n",
    "Extract the entities that you are able to find from this piece of call transcript.\n",
    " \n",
    "The output would be a structured json with only the extracted fields. Just print the exact output without any extra sentences at the end or beggining. \n",
    "No need to print any extra text. Also do not generate an answer if that is not found in the transcript.\n",
    " \n",
    "Assistant:\n",
    "\"\"\"\n",
    "    return prompt_claude\n",
    "\n",
    "# Lambda handler to intgerate with AWS\n",
    "def lambda_handler(event,context):\n",
    "    final_transcript = \"\"\n",
    "    for i in range(len(event['Records'])):\n",
    "        final_transcript += \"\\n\" + data_preprocessing(event['Records'][i])\n",
    "    prompt_enrollment = enrollment_prompt_generator(final_transcript,entities)\n",
    "    enrollment_data = load_claude2(bedrock_runtime,prompt_enrollment,0,0.9,1)\n",
    "    json_data = data_postprocessing(enrollment_data)\n",
    "    enrollment_json_object = json.loads(json_data)\n",
    "    return {\"statusCode\": 200,\"body\": json.dumps(enrollment_json_object)}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p310",
   "language": "python",
   "name": "conda_tensorflow2_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
